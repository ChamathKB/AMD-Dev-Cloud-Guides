{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9815a99d-2086-4907-809a-b6a5dbbb0f28",
   "metadata": {},
   "source": [
    "### Clone the Megatron-LM repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47e4d1-3a8d-4774-b50a-e5d0b7642845",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ROCm/Megatron-LM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e48c25-dbdf-4040-8546-2471773c2617",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "`datasets` library version 4.0.0 or later has deprecated support for loading datasets using Python scripts.\n",
    "Use `datasets==3.6.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1224d92d-3656-4ddf-8df1-b1f94757897e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure: Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 74004228\n",
      "})\n",
      "Sample Data: {'text': 'usually , he would be tearing around the living room , playing with his toys .'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bookcorpus/bookcorpus\", trust_remote_code=True, split=\"train\")\n",
    "\n",
    "print(\"Dataset Structure:\", dataset)\n",
    "print(\"Sample Data:\", dataset[0])  # Access the first record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531448a-e510-477e-9d4e-c16784252eea",
   "metadata": {},
   "source": [
    "#### Convert to the JSONL format\n",
    "Megatron-LMâ€™s preprocessing script requires that the input be in JSONL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983abedd-6f4d-40c0-b722-13407381747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving dataset to JSONL: 100% 74004228/74004228 [14:54<00:00, 82686.48record/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to bookcorpus.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_file = \"bookcorpus.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for record in tqdm(dataset, desc=\"Saving dataset to JSONL\", unit=\"record\"):\n",
    "        json.dump({\"text\": record[\"text\"]}, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8864a792-f38c-4585-b642-9175e88d50ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'usually , he would be tearing around the living room , playing with his toys .'}\n",
      "{'text': 'but just one look at a minion sent him practically catatonic .'}\n",
      "{'text': \"that had been megan 's plan when she got him dressed earlier .\"}\n",
      "{'text': \"he 'd seen the movie almost by mistake , considering he was a little young for the pg cartoon , but with older cousins , along with her brothers , mason was often exposed to things that were older .\"}\n",
      "{'text': 'she liked to think being surrounded by adults and older kids was one reason why he was a such a good talker for his age .'}\n"
     ]
    }
   ],
   "source": [
    "# inspect convertion\n",
    "with open(output_file, \"r\") as f:\n",
    "    for i in range(5):\n",
    "        print(json.loads(f.readline()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e625c-bc01-4676-ad8a-24b6afa8bd81",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b858eca7-7456-4d5f-aea9-1cb8f3578d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:290: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias, allreduce_dgrad):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:301: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:393: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:433: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\n",
      "  warnings.warn(\"Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\", UserWarning)\n",
      "/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0\n",
      "  warnings.warn(self.msg)\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron plugin due to: ImportError(\"cannot import name 'get_tensor_model_parallel_group_if_none' from 'megatron.core.utils' (/shared-docker/Megatron-LM/megatron/core/utils.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron_eagle plugin due to: ImportError(\"cannot import name 'get_expert_tensor_parallel_world_size' from 'megatron.core.parallel_state' (/shared-docker/Megatron-LM/megatron/core/parallel_state.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "Opening bookcorpus_ss_0.jsonl\n",
      "Opening bookcorpus_ss_1.jsonl\n",
      "Time to startup: 0.6142144203186035\n",
      "Time to startup: 0.6443839073181152\n",
      "Processed 1000000 documents (37069.8632136344 docs/s, 2.791395988928492 MB/s).\n",
      "Processed 1000000 documents (35234.65604983583 docs/s, 2.653956978394102 MB/s).\n",
      "Processed 2000000 documents (38052.842540226724 docs/s, 2.7282299251748356 MB/s).\n",
      "Processed 2000000 documents (36218.01116704971 docs/s, 2.597324092267478 MB/s).\n",
      "Processed 3000000 documents (38118.880584453924 docs/s, 2.737452936387159 MB/s).\n",
      "Processed 3000000 documents (36661.62678189521 docs/s, 2.63371720876368 MB/s).\n",
      "Processed 4000000 documents (38249.964956032556 docs/s, 2.7380023805001623 MB/s).\n",
      "Processed 4000000 documents (37073.37384286992 docs/s, 2.6544568517148686 MB/s).\n",
      "Processed 5000000 documents (38424.923196949094 docs/s, 2.714886268089049 MB/s).\n",
      "Processed 5000000 documents (37484.51036284633 docs/s, 2.6490812339264527 MB/s).\n",
      "Processed 6000000 documents (38206.51811370772 docs/s, 2.7361237016135815 MB/s).\n",
      "Processed 6000000 documents (37392.77519607515 docs/s, 2.6781376980969336 MB/s).\n",
      "Processed 7000000 documents (38110.3405436918 docs/s, 2.753461735614393 MB/s).\n",
      "Processed 7000000 documents (37318.9859439542 docs/s, 2.695714148979076 MB/s).\n",
      "Processed 8000000 documents (38197.01600315179 docs/s, 2.763271112496126 MB/s).\n",
      "Processed 8000000 documents (37425.358582300694 docs/s, 2.707055262610959 MB/s).\n",
      "Processed 9000000 documents (38265.8865224817 docs/s, 2.7677145020071245 MB/s).\n",
      "Processed 9000000 documents (37547.16490877205 docs/s, 2.715067737298869 MB/s).\n",
      "Processed 10000000 documents (38318.267887676775 docs/s, 2.777240923812607 MB/s).\n",
      "Processed 10000000 documents (37574.59675303817 docs/s, 2.7230084864353654 MB/s).\n",
      "Processed 11000000 documents (38317.58424980619 docs/s, 2.790457688259068 MB/s).\n",
      "Processed 11000000 documents (37577.977488886456 docs/s, 2.7362859641051047 MB/s).\n",
      "Processed 12000000 documents (38353.69740283255 docs/s, 2.788938476122694 MB/s).\n",
      "Processed 12000000 documents (37610.364835046326 docs/s, 2.7346222672552094 MB/s).\n",
      "Processed 13000000 documents (38318.756426611755 docs/s, 2.7841398408061653 MB/s).\n",
      "Processed 13000000 documents (37577.34001730089 docs/s, 2.7298168597674737 MB/s).\n",
      "Processed 14000000 documents (38317.7792496416 docs/s, 2.7809801203033637 MB/s).\n",
      "Processed 14000000 documents (37608.9275519048 docs/s, 2.7291232747764287 MB/s).\n",
      "Processed 15000000 documents (38349.7754637402 docs/s, 2.7750648339139246 MB/s).\n",
      "Processed 15000000 documents (37590.071772851414 docs/s, 2.719510797263646 MB/s).\n",
      "Processed 16000000 documents (38399.299033792 docs/s, 2.773273293749404 MB/s).\n",
      "Processed 16000000 documents (37516.90628267601 docs/s, 2.709059356574859 MB/s).\n",
      "Processed 17000000 documents (38393.38271451018 docs/s, 2.770524439099337 MB/s).\n",
      "Processed 17000000 documents (37282.808953400796 docs/s, 2.689994269133921 MB/s).\n",
      "Processed 18000000 documents (38329.407298372586 docs/s, 2.7816110138823946 MB/s).\n",
      "Processed 18000000 documents (37041.97687770919 docs/s, 2.6877041354492786 MB/s).\n",
      "Processed 19000000 documents (38275.080734377945 docs/s, 2.78468740200259 MB/s).\n",
      "Processed 19000000 documents (36976.57652710553 docs/s, 2.689685256850218 MB/s).\n",
      "Processed 20000000 documents (38267.200551950766 docs/s, 2.7862932410400463 MB/s).\n",
      "Processed 20000000 documents (36969.20189495418 docs/s, 2.6911171854268408 MB/s).\n",
      "Processed 21000000 documents (38253.595094912984 docs/s, 2.786727333575445 MB/s).\n",
      "Processed 21000000 documents (36949.25839824614 docs/s, 2.691054559819449 MB/s).\n",
      "Processed 22000000 documents (38263.01907534243 docs/s, 2.784151515124725 MB/s).\n",
      "Processed 22000000 documents (36974.094410147794 docs/s, 2.68976663685446 MB/s).\n",
      "Processed 23000000 documents (38232.596664241035 docs/s, 2.7805793381663864 MB/s).\n",
      "Processed 23000000 documents (37000.86001490882 docs/s, 2.690343473528362 MB/s).\n",
      "Processed 24000000 documents (38222.72847820227 docs/s, 2.784326393108228 MB/s).\n",
      "Processed 24000000 documents (37050.693646605316 docs/s, 2.69820059230724 MB/s).\n",
      "Processed 25000000 documents (38211.684255942244 docs/s, 2.79163306936329 MB/s).\n",
      "Processed 25000000 documents (37065.6464555235 docs/s, 2.707265878168837 MB/s).\n",
      "Processed 26000000 documents (38195.578707964974 docs/s, 2.796267619835139 MB/s).\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (197464 > 131072). Running this sequence through the model will result in indexing errors\n",
      "Processed 26000000 documents (37054.896219919785 docs/s, 2.712197620183587 MB/s).\n",
      "Processed 27000000 documents (38131.98818219105 docs/s, 2.802559168568998 MB/s).\n",
      "Processed 27000000 documents (37074.908437133134 docs/s, 2.723740151117738 MB/s).\n",
      "Processed 28000000 documents (38169.17128931483 docs/s, 2.804820532111354 MB/s).\n",
      "Processed 28000000 documents (37133.19301223348 docs/s, 2.727575341872781 MB/s).\n",
      "Processed 29000000 documents (38195.35415496251 docs/s, 2.8042362643636967 MB/s).\n",
      "Processed 29000000 documents (37176.66658623299 docs/s, 2.7284663259028927 MB/s).\n",
      "Processed 30000000 documents (38220.446366237564 docs/s, 2.801956899324663 MB/s).\n",
      "Processed 30000000 documents (37209.39862647738 docs/s, 2.72686781226671 MB/s).\n",
      "Processed 31000000 documents (38227.52390362453 docs/s, 2.7978827180603982 MB/s).\n",
      "Processed 31000000 documents (37274.905295343764 docs/s, 2.7270704427817876 MB/s).\n",
      "Processed 32000000 documents (38281.246526139825 docs/s, 2.7947522270831557 MB/s).\n",
      "Processed 32000000 documents (37346.29107773225 docs/s, 2.7253277741715527 MB/s).\n",
      "Processed 33000000 documents (38322.74115904558 docs/s, 2.7948749583529064 MB/s).\n",
      "Processed 33000000 documents (37348.77083466148 docs/s, 2.7228156607850003 MB/s).\n",
      "Processed 34000000 documents (38354.04581402704 docs/s, 2.795670176178114 MB/s).\n",
      "Processed 34000000 documents (37300.11647152722 docs/s, 2.7178573891831626 MB/s).\n",
      "Processed 35000000 documents (38376.78158536666 docs/s, 2.7956224101435327 MB/s).\n",
      "Processed 36000000 documents (38385.39792777666 docs/s, 2.7961038312711093 MB/s).\n",
      "Processed 35000000 documents (37263.45823674052 docs/s, 2.7135476272114754 MB/s).\n",
      "Processed 37000000 documents (38380.21950301198 docs/s, 2.794888224713459 MB/s).\n",
      "Processed 36000000 documents (37221.37884258062 docs/s, 2.710388140351387 MB/s).\n",
      "Processed 37000000 documents (37243.61332989204 docs/s, 2.7111937149344367 MB/s).\n",
      "INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from output/bookcorpus_0_text_sentence.idx\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the sequence lengths\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the sequence pointers\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the document indices\n",
      "INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 37078626\n",
      "INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 37002114\n",
      "INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from output/bookcorpus_1_text_sentence.idx\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the sequence lengths\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the sequence pointers\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the document indices\n",
      "INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 37078465\n",
      "INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 37002114\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p output\n",
    "!python Megatron-LM/tools/preprocess_data.py \\\n",
    "    --input bookcorpus.jsonl \\\n",
    "    --json-keys text \\\n",
    "    --output-prefix output/bookcorpus \\\n",
    "    --tokenizer-type HuggingFaceTokenizer \\\n",
    "    --tokenizer-model \"meta-llama/Llama-3.1-8B\"\\\n",
    "    --workers 4 \\\n",
    "    --append-eod \\\n",
    "    --partitions 2 \\\n",
    "    --log-interval 1000000 \\\n",
    "    --split-sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f870f2-6b6b-48d2-a966-c24486040e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bookcorpus_0_text_sentence.bin\tbookcorpus_1_text_sentence.idx\n",
      "bookcorpus_0_text_sentence.idx\tbookcorpus_text_sentence.bin\n",
      "bookcorpus_1_text_sentence.bin\tbookcorpus_text_sentence.idx\n"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "!ls output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbcafd3-94ad-419d-8a62-56fad50e10bd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9efb2cb6-2977-475a-814f-a045e9d2e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TOKENIZER_MODEL=\"meta-llama/Llama-3.1-8B\"\n",
    "!export DATA_PATH=\"output/bookcorpus_text_sentence\"\n",
    "!export SAVE_CKPT_PATH=\"checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f077878-7951-4173-bcc2-aa92601885ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples/llama/train_llama3.sh: line 31: export: --: invalid option\n",
      "export: usage: export [-fn] [name[=value] ...] or export -p\n",
      "examples/llama/train_llama3.sh: line 31: export: --: invalid option\n",
      "export: usage: export [-fn] [name[=value] ...] or export -p\n",
      "NO_TRAINING=0\n",
      "Single node setup, skipping NCCL and GLOO socket interface settings.\n",
      "experiment/1nodes_rank0_train_8B_mbs2_bs64_tp1_pp1_cp1_iter10/TE_FP8_0/2025-10-09_19-21-40/output_perf.log\n",
      "[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:290: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias, allreduce_dgrad):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:301: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:393: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:433: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\n",
      "  warnings.warn(\"Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\", UserWarning)\n",
      "/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0\n",
      "  warnings.warn(self.msg)\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron plugin due to: ImportError(\"cannot import name 'get_tensor_model_parallel_group_if_none' from 'megatron.core.utils' (/shared-docker/Megatron-LM/megatron/core/utils.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron_eagle plugin due to: ImportError(\"cannot import name 'get_expert_tensor_parallel_world_size' from 'megatron.core.parallel_state' (/shared-docker/Megatron-LM/megatron/core/parallel_state.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "using world size: 1, data-parallel size: 1, context-parallel size: 1, tensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0\n",
      "WARNING: overriding default arguments for tokenizer_type:GPT2BPETokenizer                        with tokenizer_type:HuggingFaceTokenizer\n",
      "accumulate and all-reduce gradients in fp32 for bfloat16 data type.\n",
      "using torch.bfloat16 for parameters ...\n",
      "------------------------ arguments ------------------------\n",
      "  accumulate_allreduce_grads_in_fp32 .............. True\n",
      "  adam_beta1 ...................................... 0.9\n",
      "  adam_beta2 ...................................... 0.999\n",
      "  adam_eps ........................................ 1e-08\n",
      "  add_bias_linear ................................. False\n",
      "  add_position_embedding .......................... False\n",
      "  add_qkv_bias .................................... False\n",
      "  adlr_autoresume ................................. False\n",
      "  adlr_autoresume_interval ........................ 1000\n",
      "  align_grad_reduce ............................... True\n",
      "  align_param_gather .............................. False\n",
      "  app_tag_run_name ................................ None\n",
      "  app_tag_run_version ............................. 0.0.0\n",
      "  apply_layernorm_1p .............................. False\n",
      "  apply_query_key_layer_scaling ................... False\n",
      "  apply_residual_connection_post_layernorm ........ False\n",
      "  apply_rope_fusion ............................... True\n",
      "  async_save ...................................... None\n",
      "  async_tensor_model_parallel_allreduce ........... False\n",
      "  attention_dropout ............................... 0.0\n",
      "  attention_softmax_in_fp32 ....................... False\n",
      "  auto_detect_ckpt_format ......................... False\n",
      "  barrier_with_L1_time ............................ True\n",
      "  bert_binary_head ................................ True\n",
      "  bert_embedder_type .............................. megatron\n",
      "  bert_load ....................................... None\n",
      "  bf16 ............................................ True\n",
      "  bias_dropout_fusion ............................. True\n",
      "  bias_gelu_fusion ................................ False\n",
      "  bias_swiglu_fusion .............................. True\n",
      "  biencoder_projection_dim ........................ 0\n",
      "  biencoder_shared_query_context_model ............ False\n",
      "  block_data_path ................................. None\n",
      "  calculate_per_token_loss ........................ False\n",
      "  check_for_nan_in_loss_and_grad .................. True\n",
      "  check_weight_hash_across_dp_replicas_interval ... None\n",
      "  ckpt_assume_constant_structure .................. False\n",
      "  ckpt_convert_format ............................. None\n",
      "  ckpt_convert_save ............................... None\n",
      "  ckpt_convert_update_legacy_dist_opt_format ...... False\n",
      "  ckpt_format ..................................... torch_dist\n",
      "  ckpt_fully_parallel_load ........................ False\n",
      "  ckpt_fully_parallel_save ........................ True\n",
      "  ckpt_fully_parallel_save_deprecated ............. False\n",
      "  ckpt_step ....................................... None\n",
      "  classes_fraction ................................ 1.0\n",
      "  clip_grad ....................................... 1.0\n",
      "  clone_scatter_output_in_embedding ............... True\n",
      "  config_logger_dir ............................... \n",
      "  consumed_train_samples .......................... 0\n",
      "  consumed_valid_samples .......................... 0\n",
      "  context_parallel_size ........................... 1\n",
      "  create_attention_mask_in_dataloader ............. True\n",
      "  cross_entropy_loss_fusion ....................... False\n",
      "  data_cache_path ................................. None\n",
      "  data_parallel_random_init ....................... False\n",
      "  data_parallel_size .............................. 1\n",
      "  data_path ....................................... None\n",
      "  data_per_class_fraction ......................... 1.0\n",
      "  data_sharding ................................... True\n",
      "  dataloader_type ................................. cyclic\n",
      "  ddp_average_in_collective ....................... False\n",
      "  ddp_bucket_size ................................. None\n",
      "  decoder_first_pipeline_num_layers ............... None\n",
      "  decoder_last_pipeline_num_layers ................ None\n",
      "  decoder_num_layers .............................. None\n",
      "  decoder_seq_length .............................. None\n",
      "  decoupled_lr .................................... None\n",
      "  decoupled_min_lr ................................ None\n",
      "  decrease_batch_size_if_needed ................... False\n",
      "  defer_embedding_wgrad_compute ................... False\n",
      "  deprecated_use_mcore_models ..................... True\n",
      "  deterministic_mode .............................. False\n",
      "  dino_bottleneck_size ............................ 256\n",
      "  dino_freeze_last_layer .......................... 1\n",
      "  dino_head_hidden_size ........................... 2048\n",
      "  dino_local_crops_number ......................... 10\n",
      "  dino_local_img_size ............................. 96\n",
      "  dino_norm_last_layer ............................ False\n",
      "  dino_teacher_temp ............................... 0.07\n",
      "  dino_warmup_teacher_temp ........................ 0.04\n",
      "  dino_warmup_teacher_temp_epochs ................. 30\n",
      "  disable_straggler_on_startup .................... False\n",
      "  disable_te_fused_rope ........................... False\n",
      "  dist_ckpt_format_deprecated ..................... None\n",
      "  dist_ckpt_strictness ............................ assume_ok_unexpected\n",
      "  distribute_saved_activations .................... False\n",
      "  distributed_backend ............................. nccl\n",
      "  distributed_timeout_minutes ..................... 120\n",
      "  embedding_path .................................. None\n",
      "  empty_unused_memory_level ....................... 0\n",
      "  enable_ft_package ............................... False\n",
      "  enable_one_logger ............................... True\n",
      "  encoder_num_layers .............................. 32\n",
      "  encoder_pipeline_model_parallel_size ............ 0\n",
      "  encoder_seq_length .............................. 4096\n",
      "  encoder_tensor_model_parallel_size .............. 0\n",
      "  end_weight_decay ................................ 0.1\n",
      "  eod_mask_loss ................................... False\n",
      "  eval_interval ................................... 320000\n",
      "  eval_iters ...................................... -1\n",
      "  evidence_data_path .............................. None\n",
      "  exit_duration_in_mins ........................... None\n",
      "  exit_interval ................................... None\n",
      "  exit_on_missing_checkpoint ...................... False\n",
      "  exit_signal_handler ............................. False\n",
      "  expert_model_parallel_size ...................... 1\n",
      "  ffn_hidden_size ................................. 14336\n",
      "  finetune ........................................ False\n",
      "  fp16 ............................................ False\n",
      "  fp16_lm_cross_entropy ........................... False\n",
      "  fp32_residual_connection ........................ False\n",
      "  fp8 ............................................. None\n",
      "  fp8_amax_compute_algo ........................... most_recent\n",
      "  fp8_amax_history_len ............................ 1\n",
      "  fp8_interval .................................... 1\n",
      "  fp8_margin ...................................... 0\n",
      "  fp8_param_gather ................................ False\n",
      "  fp8_wgrad ....................................... True\n",
      "  global_batch_size ............................... 64\n",
      "  gradient_accumulation_fusion .................... False\n",
      "  group_query_attention ........................... True\n",
      "  head_lr_mult .................................... 1.0\n",
      "  hidden_dropout .................................. 0.0\n",
      "  hidden_size ..................................... 4096\n",
      "  hybrid_attention_ratio .......................... 0.0\n",
      "  hybrid_mlp_ratio ................................ 0.0\n",
      "  hybrid_override_pattern ......................... None\n",
      "  hysteresis ...................................... 2\n",
      "  ict_head_size ................................... None\n",
      "  ict_load ........................................ None\n",
      "  img_h ........................................... 224\n",
      "  img_w ........................................... 224\n",
      "  indexer_batch_size .............................. 128\n",
      "  indexer_log_interval ............................ 1000\n",
      "  inference_batch_times_seqlen_threshold .......... 512\n",
      "  init_method_std ................................. 0.02\n",
      "  init_method_xavier_uniform ...................... False\n",
      "  initial_loss_scale .............................. 4294967296\n",
      "  iter_per_epoch .................................. 1250\n",
      "  kv_channels ..................................... 128\n",
      "  kv_lora_rank .................................... 32\n",
      "  lazy_mpu_init ................................... None\n",
      "  load ............................................ None\n",
      "  local_rank ...................................... 0\n",
      "  log_interval .................................... 1\n",
      "  log_loss_scale_to_tensorboard ................... True\n",
      "  log_memory_to_tensorboard ....................... False\n",
      "  log_num_zeros_in_grad ........................... False\n",
      "  log_params_norm ................................. False\n",
      "  log_progress .................................... False\n",
      "  log_straggler ................................... False\n",
      "  log_throughput .................................. True\n",
      "  log_timers_to_tensorboard ....................... False\n",
      "  log_validation_ppl_to_tensorboard ............... False\n",
      "  log_world_size_to_tensorboard ................... False\n",
      "  logging_level ................................... None\n",
      "  loss_scale ...................................... None\n",
      "  loss_scale_window ............................... 1000\n",
      "  lr .............................................. 0.0001\n",
      "  lr_decay_iters .................................. 320000\n",
      "  lr_decay_samples ................................ None\n",
      "  lr_decay_style .................................. cosine\n",
      "  lr_warmup_fraction .............................. None\n",
      "  lr_warmup_init .................................. 0.0\n",
      "  lr_warmup_iters ................................. 0\n",
      "  lr_warmup_samples ............................... 0\n",
      "  lr_wsd_decay_iters .............................. None\n",
      "  lr_wsd_decay_samples ............................ None\n",
      "  lr_wsd_decay_style .............................. exponential\n",
      "  make_vocab_size_divisible_by .................... 128\n",
      "  manual_gc ....................................... False\n",
      "  manual_gc_eval .................................. True\n",
      "  manual_gc_interval .............................. 0\n",
      "  mask_factor ..................................... 1.0\n",
      "  mask_prob ....................................... 0.15\n",
      "  mask_type ....................................... random\n",
      "  masked_softmax_fusion ........................... False\n",
      "  max_position_embeddings ......................... 128000\n",
      "  max_tokens_to_oom ............................... 12000\n",
      "  merge_file ...................................... None\n",
      "  micro_batch_size ................................ 2\n",
      "  min_loss_scale .................................. 1.0\n",
      "  min_lr .......................................... 1e-05\n",
      "  mmap_bin_files .................................. True\n",
      "  mock_data ....................................... True\n",
      "  moe_aux_loss_coeff .............................. 0.0\n",
      "  moe_expert_capacity_factor ...................... None\n",
      "  moe_extended_tp ................................. False\n",
      "  moe_grouped_gemm ................................ False\n",
      "  moe_input_jitter_eps ............................ None\n",
      "  moe_layer_recompute ............................. False\n",
      "  moe_pad_expert_input_to_capacity ................ False\n",
      "  moe_per_layer_logging ........................... False\n",
      "  moe_router_load_balancing_type .................. aux_loss\n",
      "  moe_router_pre_softmax .......................... False\n",
      "  moe_router_topk ................................. 2\n",
      "  moe_shared_expert_intermediate_size ............. None\n",
      "  moe_shared_expert_overlap ....................... False\n",
      "  moe_token_dispatcher_type ....................... allgather\n",
      "  moe_token_drop_policy ........................... probs\n",
      "  moe_use_upcycling ............................... False\n",
      "  moe_z_loss_coeff ................................ None\n",
      "  multi_latent_attention .......................... False\n",
      "  nccl_communicator_config_path ................... None\n",
      "  no_load_optim ................................... None\n",
      "  no_load_rng ..................................... None\n",
      "  no_persist_layer_norm ........................... False\n",
      "  no_save_optim ................................... True\n",
      "  no_save_rng ..................................... None\n",
      "  non_persistent_ckpt_type ........................ None\n",
      "  non_persistent_global_ckpt_dir .................. None\n",
      "  non_persistent_local_ckpt_algo .................. fully_parallel\n",
      "  non_persistent_local_ckpt_dir ................... None\n",
      "  non_persistent_save_interval .................... None\n",
      "  norm_epsilon .................................... 1e-05\n",
      "  normalization ................................... RMSNorm\n",
      "  num_attention_heads ............................. 32\n",
      "  num_channels .................................... 3\n",
      "  num_classes ..................................... 1000\n",
      "  num_dataset_builder_threads ..................... 1\n",
      "  num_experts ..................................... None\n",
      "  num_layers ...................................... 32\n",
      "  num_layers_per_virtual_pipeline_stage ........... None\n",
      "  num_query_groups ................................ 8\n",
      "  num_workers ..................................... 8\n",
      "  one_logger_async ................................ False\n",
      "  one_logger_project .............................. megatron-lm\n",
      "  one_logger_run_name ............................. None\n",
      "  onnx_safe ....................................... None\n",
      "  openai_gelu ..................................... False\n",
      "  optimizer ....................................... adam\n",
      "  output_bert_embeddings .......................... False\n",
      "  overlap_grad_reduce ............................. True\n",
      "  overlap_p2p_comm ................................ False\n",
      "  overlap_param_gather ............................ True\n",
      "  overlap_param_gather_with_optimizer_step ........ False\n",
      "  override_opt_param_scheduler .................... False\n",
      "  params_dtype .................................... torch.bfloat16\n",
      "  patch_dim ....................................... 16\n",
      "  perform_initialization .......................... True\n",
      "  pipeline_model_parallel_size .................... 1\n",
      "  pipeline_model_parallel_split_rank .............. None\n",
      "  position_embedding_type ......................... rope\n",
      "  pretrained_checkpoint ........................... None\n",
      "  profile ......................................... False\n",
      "  profile_ranks ................................... [0]\n",
      "  profile_step_end ................................ 12\n",
      "  profile_step_start .............................. 10\n",
      "  q_lora_rank ..................................... None\n",
      "  qk_head_dim ..................................... 128\n",
      "  qk_layernorm .................................... False\n",
      "  qk_pos_emb_head_dim ............................. 64\n",
      "  query_in_block_prob ............................. 0.1\n",
      "  rampup_batch_size ............................... None\n",
      "  rank ............................................ 0\n",
      "  recompute_granularity ........................... None\n",
      "  recompute_method ................................ None\n",
      "  recompute_num_layers ............................ None\n",
      "  renormalize_blend_weights ....................... False\n",
      "  reset_attention_mask ............................ False\n",
      "  reset_position_ids .............................. False\n",
      "  retriever_report_topk_accuracies ................ []\n",
      "  retriever_score_scaling ......................... False\n",
      "  retriever_seq_length ............................ 256\n",
      "  retro_add_retriever ............................. False\n",
      "  retro_attention_gate ............................ 1\n",
      "  retro_cyclic_train_iters ........................ None\n",
      "  retro_encoder_attention_dropout ................. 0.1\n",
      "  retro_encoder_hidden_dropout .................... 0.1\n",
      "  retro_encoder_layers ............................ 2\n",
      "  retro_num_neighbors ............................. 2\n",
      "  retro_num_retrieved_chunks ...................... 2\n",
      "  retro_project_dir ............................... None\n",
      "  retro_verify_neighbor_count ..................... True\n",
      "  rotary_base ..................................... 10000\n",
      "  rotary_interleaved .............................. False\n",
      "  rotary_percent .................................. 1.0\n",
      "  rotary_scaling_factor ........................... 1.0\n",
      "  rotary_seq_len_interpolation_factor ............. None\n",
      "  s3_cache_path ................................... None\n",
      "  sample_rate ..................................... 1.0\n",
      "  save ............................................ None\n",
      "  save_interval ................................... 5000\n",
      "  scatter_gather_tensors_in_pipeline .............. True\n",
      "  seed ............................................ 1234\n",
      "  seq_length ...................................... 4096\n",
      "  sequence_parallel ............................... False\n",
      "  sgd_momentum .................................... 0.9\n",
      "  short_seq_prob .................................. 0.1\n",
      "  skip_train ...................................... False\n",
      "  skipped_train_samples ........................... 0\n",
      "  spec ............................................ None\n",
      "  split ........................................... None\n",
      "  squared_relu .................................... False\n",
      "  standalone_embedding_stage ...................... False\n",
      "  start_weight_decay .............................. 0.1\n",
      "  straggler_ctrlr_port ............................ 65535\n",
      "  straggler_minmax_count .......................... 1\n",
      "  swiglu .......................................... True\n",
      "  swin_backbone_type .............................. tiny\n",
      "  tensor_model_parallel_size ...................... 1\n",
      "  tensorboard_dir ................................. experiment/1nodes_rank0_train_8B_mbs2_bs64_tp1_pp1_cp1_iter10/TE_FP8_0/2025-10-09_19-21-40\n",
      "  tensorboard_log_interval ........................ 1\n",
      "  tensorboard_queue_size .......................... 1000\n",
      "  test_data_path .................................. None\n",
      "  test_mode ....................................... False\n",
      "  tiktoken_num_special_tokens ..................... 1000\n",
      "  tiktoken_pattern ................................ None\n",
      "  tiktoken_special_tokens ......................... None\n",
      "  timing_log_level ................................ 0\n",
      "  timing_log_option ............................... minmax\n",
      "  titles_data_path ................................ None\n",
      "  tokenizer_model ................................. meta-llama/Llama-3.1-8B\n",
      "  tokenizer_type .................................. HuggingFaceTokenizer\n",
      "  tp_comm_bootstrap_backend ....................... nccl\n",
      "  tp_comm_bulk_dgrad .............................. True\n",
      "  tp_comm_bulk_wgrad .............................. True\n",
      "  tp_comm_overlap ................................. False\n",
      "  tp_comm_overlap_ag .............................. True\n",
      "  tp_comm_overlap_cfg ............................. None\n",
      "  tp_comm_overlap_rs .............................. True\n",
      "  tp_comm_overlap_rs_dgrad ........................ False\n",
      "  tp_comm_split_ag ................................ True\n",
      "  tp_comm_split_rs ................................ True\n",
      "  train_data_path ................................. None\n",
      "  train_iters ..................................... 10\n",
      "  train_samples ................................... None\n",
      "  train_sync_interval ............................. None\n",
      "  transformer_impl ................................ transformer_engine\n",
      "  transformer_pipeline_model_parallel_size ........ 1\n",
      "  untie_embeddings_and_output_weights ............. True\n",
      "  use_checkpoint_args ............................. False\n",
      "  use_checkpoint_opt_param_scheduler .............. False\n",
      "  use_cpu_initialization .......................... None\n",
      "  use_dist_ckpt ................................... True\n",
      "  use_dist_ckpt_deprecated ........................ False\n",
      "  use_distributed_optimizer ....................... True\n",
      "  use_flash_attn .................................. True\n",
      "  use_legacy_models ............................... False\n",
      "  use_one_sent_docs ............................... False\n",
      "  use_pytorch_profiler ............................ False\n",
      "  use_ring_exchange_p2p ........................... False\n",
      "  use_rope_scaling ................................ False\n",
      "  use_rotary_position_embeddings .................. False\n",
      "  use_tp_pp_dp_mapping ............................ False\n",
      "  v_head_dim ...................................... 128\n",
      "  valid_data_path ................................. None\n",
      "  variable_seq_lengths ............................ False\n",
      "  virtual_pipeline_model_parallel_size ............ None\n",
      "  vision_backbone_type ............................ vit\n",
      "  vision_pretraining .............................. False\n",
      "  vision_pretraining_type ......................... classify\n",
      "  vocab_extra_ids ................................. 0\n",
      "  vocab_file ...................................... None\n",
      "  vocab_size ...................................... None\n",
      "  wandb_exp_name .................................. \n",
      "  wandb_project ................................... \n",
      "  wandb_save_dir .................................. \n",
      "  weight_decay .................................... 0.1\n",
      "  weight_decay_incr_style ......................... constant\n",
      "  wgrad_deferral_limit ............................ 0\n",
      "  world_size ...................................... 1\n",
      "  yaml_cfg ........................................ None\n",
      "-------------------- end of arguments ---------------------\n",
      "INFO:megatron.core.num_microbatches_calculator:setting number of microbatches to constant 32\n",
      "> building HuggingFaceTokenizer tokenizer ...\n",
      " > padded vocab (size: 128256) with 0 dummy tokens (new size: 128256)\n",
      "> setting tensorboard ...\n",
      "WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it\n",
      "> initializing torch distributed ...\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "> initialized tensor model parallel with size 1\n",
      "> initialized pipeline model parallel with size 1\n",
      "> setting random seeds to 1234 ...\n",
      "> compiling dataset index builder ...\n",
      "make: Entering directory '/shared-docker/Megatron-LM/megatron/core/datasets'\n",
      "make: Nothing to be done for 'default'.\n",
      "make: Leaving directory '/shared-docker/Megatron-LM/megatron/core/datasets'\n",
      ">>> done with dataset index builder. Compilation time: 0.020 seconds\n",
      "WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.\n",
      "> compiling and loading fused kernels ...\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank0]:[W1009 19:21:48.273509557 ProcessGroupNCCL.cpp:5059] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.\n",
      ">>> done with compiling and loading fused kernels. Compilation time: 1.763 seconds\n",
      "[rank0]:[W1009 19:21:50.036177117 init.cpp:772] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())\n",
      "time to initialize megatron (seconds): 3.308\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[after megatron is initialized] datetime: 2025-10-09 19:21:51 \n",
      "building GPT model ...\n",
      " > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 8030261248\n",
      "INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=False, fp8_param_gather=False)\n",
      "INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 98\n",
      "Params for bucket 1 (525336576 elements):\n",
      "\tmodule.output_layer.weight\n",
      "Params for bucket 2 (58724352 elements):\n",
      "\tmodule.decoder.final_layernorm.weight\n",
      "\tmodule.decoder.layers.31.mlp.linear_fc2.weight\n",
      "Params for bucket 3 (117440512 elements):\n",
      "\tmodule.decoder.layers.31.mlp.linear_fc1.weight\n",
      "Params for bucket 4 (41951232 elements):\n",
      "\tmodule.decoder.layers.31.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.31.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.31.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.31.self_attention.linear_proj.weight\n",
      "Params for bucket 5 (58720256 elements):\n",
      "\tmodule.decoder.layers.30.mlp.linear_fc2.weight\n",
      "Params for bucket 6 (117440512 elements):\n",
      "\tmodule.decoder.layers.30.mlp.linear_fc1.weight\n",
      "Params for bucket 7 (41951232 elements):\n",
      "\tmodule.decoder.layers.30.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.30.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.30.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.30.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 8 (58720256 elements):\n",
      "\tmodule.decoder.layers.29.mlp.linear_fc2.weight\n",
      "Params for bucket 9 (117440512 elements):\n",
      "\tmodule.decoder.layers.29.mlp.linear_fc1.weight\n",
      "Params for bucket 10 (41951232 elements):\n",
      "\tmodule.decoder.layers.29.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.29.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.29.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.29.self_attention.linear_proj.weight\n",
      "Params for bucket 11 (58720256 elements):\n",
      "\tmodule.decoder.layers.28.mlp.linear_fc2.weight\n",
      "Params for bucket 12 (117440512 elements):\n",
      "\tmodule.decoder.layers.28.mlp.linear_fc1.weight\n",
      "Params for bucket 13 (41951232 elements):\n",
      "\tmodule.decoder.layers.28.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.28.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.28.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.28.self_attention.linear_proj.weight\n",
      "Params for bucket 14 (58720256 elements):\n",
      "\tmodule.decoder.layers.27.mlp.linear_fc2.weight\n",
      "Params for bucket 15 (117440512 elements):\n",
      "\tmodule.decoder.layers.27.mlp.linear_fc1.weight\n",
      "Params for bucket 16 (41951232 elements):\n",
      "\tmodule.decoder.layers.27.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.27.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.27.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.27.self_attention.linear_proj.weight\n",
      "Params for bucket 17 (58720256 elements):\n",
      "\tmodule.decoder.layers.26.mlp.linear_fc2.weight\n",
      "Params for bucket 18 (117440512 elements):\n",
      "\tmodule.decoder.layers.26.mlp.linear_fc1.weight\n",
      "Params for bucket 19 (41951232 elements):\n",
      "\tmodule.decoder.layers.26.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.26.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.26.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.26.self_attention.linear_proj.weight\n",
      "Params for bucket 20 (58720256 elements):\n",
      "\tmodule.decoder.layers.25.mlp.linear_fc2.weight\n",
      "Params for bucket 21 (117440512 elements):\n",
      "\tmodule.decoder.layers.25.mlp.linear_fc1.weight\n",
      "Params for bucket 22 (41951232 elements):\n",
      "\tmodule.decoder.layers.25.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.25.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.25.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.25.self_attention.linear_proj.weight\n",
      "Params for bucket 23 (58720256 elements):\n",
      "\tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "Params for bucket 24 (117440512 elements):\n",
      "\tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "Params for bucket 25 (41951232 elements):\n",
      "\tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "Params for bucket 26 (58720256 elements):\n",
      "\tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "Params for bucket 27 (117440512 elements):\n",
      "\tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "Params for bucket 28 (41951232 elements):\n",
      "\tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.23.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.23.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.23.self_attention.linear_qkv.weight\n",
      "Params for bucket 29 (58720256 elements):\n",
      "\tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "Params for bucket 30 (117440512 elements):\n",
      "\tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "Params for bucket 31 (41951232 elements):\n",
      "\tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.22.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.22.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.22.self_attention.linear_proj.weight\n",
      "Params for bucket 32 (58720256 elements):\n",
      "\tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "Params for bucket 33 (117440512 elements):\n",
      "\tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "Params for bucket 34 (41951232 elements):\n",
      "\tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.21.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.21.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.21.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 35 (58720256 elements):\n",
      "\tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "Params for bucket 36 (117440512 elements):\n",
      "\tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "Params for bucket 37 (41951232 elements):\n",
      "\tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.20.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.20.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.20.self_attention.linear_proj.weight\n",
      "Params for bucket 38 (58720256 elements):\n",
      "\tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "Params for bucket 39 (117440512 elements):\n",
      "\tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "Params for bucket 40 (41951232 elements):\n",
      "\tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.19.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.19.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.19.self_attention.linear_proj.weight\n",
      "Params for bucket 41 (58720256 elements):\n",
      "\tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "Params for bucket 42 (117440512 elements):\n",
      "\tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "Params for bucket 43 (41951232 elements):\n",
      "\tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.18.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.18.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.18.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 44 (58720256 elements):\n",
      "\tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "Params for bucket 45 (117440512 elements):\n",
      "\tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "Params for bucket 46 (41951232 elements):\n",
      "\tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 47 (58720256 elements):\n",
      "\tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "Params for bucket 48 (117440512 elements):\n",
      "\tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "Params for bucket 49 (41951232 elements):\n",
      "\tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.16.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.16.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.16.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 50 (58720256 elements):\n",
      "\tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "Params for bucket 51 (117440512 elements):\n",
      "\tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "Params for bucket 52 (41951232 elements):\n",
      "\tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.15.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.15.self_attention.linear_qkv.weight\n",
      "Params for bucket 53 (58720256 elements):\n",
      "\tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "Params for bucket 54 (117440512 elements):\n",
      "\tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "Params for bucket 55 (41951232 elements):\n",
      "\tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.14.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.14.self_attention.linear_proj.weight\n",
      "Params for bucket 56 (58720256 elements):\n",
      "\tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "Params for bucket 57 (117440512 elements):\n",
      "\tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "Params for bucket 58 (41951232 elements):\n",
      "\tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.13.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.13.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 59 (58720256 elements):\n",
      "\tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "Params for bucket 60 (117440512 elements):\n",
      "\tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "Params for bucket 61 (41951232 elements):\n",
      "\tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.12.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.12.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 62 (58720256 elements):\n",
      "\tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "Params for bucket 63 (117440512 elements):\n",
      "\tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "Params for bucket 64 (41951232 elements):\n",
      "\tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.11.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.11.self_attention.linear_proj.weight\n",
      "Params for bucket 65 (58720256 elements):\n",
      "\tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "Params for bucket 66 (117440512 elements):\n",
      "\tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "Params for bucket 67 (41951232 elements):\n",
      "\tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "Params for bucket 68 (58720256 elements):\n",
      "\tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "Params for bucket 69 (117440512 elements):\n",
      "\tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "Params for bucket 70 (41951232 elements):\n",
      "\tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.9.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.9.self_attention.linear_qkv.weight\n",
      "Params for bucket 71 (58720256 elements):\n",
      "\tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "Params for bucket 72 (117440512 elements):\n",
      "\tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "Params for bucket 73 (41951232 elements):\n",
      "\tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.8.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.8.self_attention.linear_qkv.weight\n",
      "Params for bucket 74 (58720256 elements):\n",
      "\tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "Params for bucket 75 (117440512 elements):\n",
      "\tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "Params for bucket 76 (41951232 elements):\n",
      "\tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.7.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.7.self_attention.linear_qkv.weight\n",
      "Params for bucket 77 (58720256 elements):\n",
      "\tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "Params for bucket 78 (117440512 elements):\n",
      "\tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "Params for bucket 79 (41951232 elements):\n",
      "\tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.6.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.6.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 80 (58720256 elements):\n",
      "\tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "Params for bucket 81 (117440512 elements):\n",
      "\tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "Params for bucket 82 (41951232 elements):\n",
      "\tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.5.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.5.self_attention.linear_proj.weight\n",
      "Params for bucket 83 (58720256 elements):\n",
      "\tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "Params for bucket 84 (117440512 elements):\n",
      "\tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "Params for bucket 85 (41951232 elements):\n",
      "\tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.4.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.4.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 86 (58720256 elements):\n",
      "\tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "Params for bucket 87 (117440512 elements):\n",
      "\tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "Params for bucket 88 (41951232 elements):\n",
      "\tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "Params for bucket 89 (58720256 elements):\n",
      "\tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "Params for bucket 90 (117440512 elements):\n",
      "\tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "Params for bucket 91 (41951232 elements):\n",
      "\tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 92 (58720256 elements):\n",
      "\tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "Params for bucket 93 (117440512 elements):\n",
      "\tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "Params for bucket 94 (41951232 elements):\n",
      "\tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 95 (58720256 elements):\n",
      "\tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "Params for bucket 96 (117440512 elements):\n",
      "\tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "Params for bucket 97 (41951232 elements):\n",
      "\tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "Params for bucket 98 (525336576 elements):\n",
      "\tmodule.embedding.word_embeddings.weight\n",
      "INFO:megatron.core.optimizer:Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0001, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7e011ba1efb0>, config_logger_dir='')\n",
      "INFO:megatron.core.optimizer_param_scheduler:> learning rate decay style: cosine\n",
      "[after model, optimizer, and learning rate scheduler are built] datetime: 2025-10-09 19:21:51 \n",
      "> building train, validation, and test datasets ...\n",
      " > datasets target sizes (minimum size):\n",
      "    train:      640\n",
      "    validation: -64\n",
      "    test:       -64\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_config:Let mock = True, as both blend and blend_per_split are None\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split = 1,1,1, an arbitrarily even split, as mock is True\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.3333333333333333), (0.3333333333333333, 0.6666666666666666), (0.6666666666666666, 1.0)]\n",
      "> building train, validation, and test datasets for GPT ...\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=MockGPTDataset, sizes=(640, -64, -64), and config=GPTDatasetConfig(random_seed=1234, sequence_length=4096, blend=None, blend_per_split=[None, None, None], renormalize_blend_weights=False, split='1,1,1', split_matrix=[(0, 0.3333333333333333), (0.3333333333333333, 0.6666666666666666), (0.6666666666666666, 1.0)], num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=True, tokenizer=<megatron.training.tokenizer.tokenizer._HuggingFaceTokenizer object at 0x7e011c9fb730>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, s3_cache_path=None)\n",
      "INFO:megatron.core.datasets.gpt_dataset:Build and save the MockGPTDataset train indices\n",
      "WARNING:megatron.core.datasets.gpt_dataset:Unable to save the MockGPTDataset indexes because path_to_cache is None\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 16648\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1\n",
      "INFO:megatron.core.datasets.gpt_dataset:Build and save the MockGPTDataset valid indices\n",
      "WARNING:megatron.core.datasets.gpt_dataset:Unable to save the MockGPTDataset indexes because path_to_cache is None\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 16640\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1\n",
      "INFO:megatron.core.datasets.gpt_dataset:Build and save the MockGPTDataset test indices\n",
      "WARNING:megatron.core.datasets.gpt_dataset:Unable to save the MockGPTDataset indexes because path_to_cache is None\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 16671\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1\n",
      "> finished creating GPT datasets ...\n",
      "[after dataloaders are built] datetime: 2025-10-09 19:21:51 \n",
      "done with setup ...\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.\n",
      "  return func(*args, **kwargs)\n",
      "(min, max) time across ranks (ms):\n",
      "    model-and-optimizer-setup ......................: (236.80, 236.80)\n",
      "    train/valid/test-data-iterators-setup ..........: (7.13, 7.13)\n",
      "training ...\n",
      "[before the start of training step] datetime: 2025-10-09 19:21:51 \n",
      "AITER_ASM_DIR set to: /opt/venv/lib/python3.10/site-packages/transformer_engine/aiter/gfx942/\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.\n",
      "  return func(*args, **kwargs)\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:623: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.\n",
      "  warnings.warn(\n",
      "/shared-docker/Megatron-LM/megatron/core/distributed/param_and_grad_buffer.py:259: FutureWarning: `torch.distributed._reduce_scatter_base` is a private function and will be deprecated. Please use `torch.distributed.reduce_scatter_tensor` instead.\n",
      "  torch.distributed._reduce_scatter_base(\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      " [2025-10-09 19:22:33] iteration        1/      10 | consumed samples:           64 | elapsed time per iteration (ms): 42117.5 | throughput per GPU (TFLOP/s/GPU): 320.4 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.258631E+01 | loss scale: 1.0 | grad norm: 13.107 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "Number of parameters in transformer layers in billions:  6.98\n",
      "Number of parameters in embedding layers in billions: 1.05\n",
      "Total number of parameters in billions: 8.03\n",
      "Number of parameters in most loaded shard in billions: 8.0305\n",
      "Theoretical memory footprints: weight and optimizer=137853.14 MB\n",
      "[Rank 0] (after 1 iterations) memory (MB) | allocated: 138033.55859375 | max allocated: 138033.57470703125 | reserved: 149810.0 | max reserved: 149810.0\n",
      " [2025-10-09 19:22:59] iteration        2/      10 | consumed samples:          128 | elapsed time per iteration (ms): 25773.9 | throughput per GPU (TFLOP/s/GPU): 523.5 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 3.872712E+00 | loss scale: 1.0 | grad norm: 11.361 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 19:23:25] iteration        3/      10 | consumed samples:          192 | elapsed time per iteration (ms): 25812.3 | throughput per GPU (TFLOP/s/GPU): 522.7 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 9.160864E-01 | loss scale: 1.0 | grad norm: 3.976 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 19:23:51] iteration        4/      10 | consumed samples:          256 | elapsed time per iteration (ms): 25779.2 | throughput per GPU (TFLOP/s/GPU): 523.4 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 5.757737E-01 | loss scale: 1.0 | grad norm: 10.352 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 19:24:16] iteration        5/      10 | consumed samples:          320 | elapsed time per iteration (ms): 25782.9 | throughput per GPU (TFLOP/s/GPU): 523.3 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 2.551289E-01 | loss scale: 1.0 | grad norm: 1.838 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 19:24:42] iteration        6/      10 | consumed samples:          384 | elapsed time per iteration (ms): 25781.2 | throughput per GPU (TFLOP/s/GPU): 523.4 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.903217E-01 | loss scale: 1.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 19:25:08] iteration        7/      10 | consumed samples:          448 | elapsed time per iteration (ms): 25771.3 | throughput per GPU (TFLOP/s/GPU): 523.6 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.528123E-01 | loss scale: 1.0 | grad norm: 1.269 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 19:25:34] iteration        8/      10 | consumed samples:          512 | elapsed time per iteration (ms): 25815.9 | throughput per GPU (TFLOP/s/GPU): 522.6 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.051872E-01 | loss scale: 1.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 19:26:00] iteration        9/      10 | consumed samples:          576 | elapsed time per iteration (ms): 25776.2 | throughput per GPU (TFLOP/s/GPU): 523.5 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 8.984262E-02 | loss scale: 1.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 19:26:25] iteration       10/      10 | consumed samples:          640 | elapsed time per iteration (ms): 25756.3 | throughput per GPU (TFLOP/s/GPU): 523.9 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 7.867125E-02 | loss scale: 1.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "/shared-docker/Megatron-LM/megatron/core/optimizer/distrib_optimizer.py:557: UserWarning: `DistributedOptimizer.disable_pre_hook` will be deprecated in a future release. Use `DistributedDataParallel.disable_forward_pre_hook` directly.\n",
      "  warnings.warn(\n",
      "[after training is done] datetime: 2025-10-09 19:26:25 \n",
      "[rank0]:[W1009 19:26:26.513174748 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "throughput per GPU: 523.2142857142857\n",
      "elapsed time per iteration: 25788.428571428572\n",
      "tokens/GPU/s: 10165.179289\n"
     ]
    }
   ],
   "source": [
    "!cd Megatron-LM && TEE_OUTPUT=1 MBS=2 BS=64 TP=1 TE_FP8=0 SEQ_LENGTH=4096  \\\n",
    "TOKENIZER_MODEL='meta-llama/Llama-3.1-8B' MODEL_SIZE='8' \\\n",
    "bash examples/llama/train_llama3.sh --data-path ${DATA_PATH} --save ${SAVE_CKPT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58321b-7035-44b1-aead-9752c4f9e1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

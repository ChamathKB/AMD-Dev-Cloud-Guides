{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9815a99d-2086-4907-809a-b6a5dbbb0f28",
   "metadata": {},
   "source": [
    "### Clone the Megatron-LM repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47e4d1-3a8d-4774-b50a-e5d0b7642845",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ROCm/Megatron-LM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e48c25-dbdf-4040-8546-2471773c2617",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "`datasets` library version 4.0.0 or later has deprecated support for loading datasets using Python scripts.\n",
    "Use `datasets==3.6.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1224d92d-3656-4ddf-8df1-b1f94757897e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7818f0ae0aba462d98e81f111d7f895d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704824e3a2c14fdfbb9529c27f9f988b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/74004228 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure: Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 74004228\n",
      "})\n",
      "Sample Data: {'text': 'usually , he would be tearing around the living room , playing with his toys .'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bookcorpus/bookcorpus\", trust_remote_code=True, split=\"train\")\n",
    "\n",
    "print(\"Dataset Structure:\", dataset)\n",
    "print(\"Sample Data:\", dataset[0])  # Access the first record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531448a-e510-477e-9d4e-c16784252eea",
   "metadata": {},
   "source": [
    "#### Convert to the JSONL format\n",
    "Megatron-LM’s preprocessing script requires that the input be in JSONL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983abedd-6f4d-40c0-b722-13407381747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving dataset to JSONL: 100% 74004228/74004228 [15:52<00:00, 77656.02record/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to bookcorpus.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_file = \"bookcorpus.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for record in tqdm(dataset, desc=\"Saving dataset to JSONL\", unit=\"record\"):\n",
    "        json.dump({\"text\": record[\"text\"]}, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8864a792-f38c-4585-b642-9175e88d50ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'usually , he would be tearing around the living room , playing with his toys .'}\n",
      "{'text': 'but just one look at a minion sent him practically catatonic .'}\n",
      "{'text': \"that had been megan 's plan when she got him dressed earlier .\"}\n",
      "{'text': \"he 'd seen the movie almost by mistake , considering he was a little young for the pg cartoon , but with older cousins , along with her brothers , mason was often exposed to things that were older .\"}\n",
      "{'text': 'she liked to think being surrounded by adults and older kids was one reason why he was a such a good talker for his age .'}\n"
     ]
    }
   ],
   "source": [
    "# inspect convertion\n",
    "with open(output_file, \"r\") as f:\n",
    "    for i in range(5):\n",
    "        print(json.loads(f.readline()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e625c-bc01-4676-ad8a-24b6afa8bd81",
   "metadata": {},
   "source": [
    "### Preprocess the data\n",
    "*Note*: This is an example if tokenizer loaded for preprocessing, otherwise use `TOKENIZER_MODEL` variable in trianing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479a4904-206e-4a88-8ca0-0aeebc848813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-08 20:26:16--  https://huggingface.co/gpt2/resolve/main/vocab.json\n",
      "Resolving huggingface.co (huggingface.co)... 3.171.171.65, 3.171.171.104, 3.171.171.128, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.171.171.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1042301 (1018K) [text/plain]\n",
      "Saving to: ‘vocab.json’\n",
      "\n",
      "vocab.json          100%[===================>]   1018K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2025-10-08 20:26:16 (19.2 MB/s) - ‘vocab.json’ saved [1042301/1042301]\n",
      "\n",
      "--2025-10-08 20:26:16--  https://huggingface.co/gpt2/resolve/main/merges.txt\n",
      "Resolving huggingface.co (huggingface.co)... 3.171.171.128, 3.171.171.104, 3.171.171.6, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.171.171.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 456318 (446K) [text/plain]\n",
      "Saving to: ‘merges.txt’\n",
      "\n",
      "merges.txt          100%[===================>] 445.62K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2025-10-08 20:26:16 (16.0 MB/s) - ‘merges.txt’ saved [456318/456318]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download the tokenizer files\n",
    "!wget https://huggingface.co/gpt2/resolve/main/vocab.json -O vocab.json\n",
    "!wget https://huggingface.co/gpt2/resolve/main/merges.txt -O merges.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b858eca7-7456-4d5f-aea9-1cb8f3578d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:290: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias, allreduce_dgrad):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:301: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:393: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:433: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\n",
      "  warnings.warn(\"Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\", UserWarning)\n",
      "/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0\n",
      "  warnings.warn(self.msg)\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron plugin due to: ImportError(\"cannot import name 'get_tensor_model_parallel_group_if_none' from 'megatron.core.utils' (/shared-docker/Megatron-LM/megatron/core/utils.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron_eagle plugin due to: ImportError(\"cannot import name 'get_expert_tensor_parallel_world_size' from 'megatron.core.parallel_state' (/shared-docker/Megatron-LM/megatron/core/parallel_state.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "Opening bookcorpus_0.jsonl\n",
      "Opening bookcorpus_1.jsonl\n",
      "Processed 1000000 documents (192510.90471823156 docs/s, 14.12832597692662 MB/s).\n",
      "Processed 1000000 documents (188024.37020884166 docs/s, 13.803066413068835 MB/s).\n",
      "Processed 2000000 documents (192513.77201031064 docs/s, 13.43451984869808 MB/s).\n",
      "Processed 2000000 documents (188936.2168688218 docs/s, 13.188253208343863 MB/s).\n",
      "Processed 3000000 documents (192259.54275523528 docs/s, 13.439340757998671 MB/s).\n",
      "Processed 3000000 documents (186379.0682592968 docs/s, 13.03297580236802 MB/s).\n",
      "Processed 4000000 documents (193818.91850690029 docs/s, 13.503367995015601 MB/s).\n",
      "Processed 4000000 documents (189192.20861101587 docs/s, 13.184529470645844 MB/s).\n",
      "Processed 5000000 documents (194297.69896025097 docs/s, 13.356547727076713 MB/s).\n",
      "Processed 5000000 documents (191847.32131163232 docs/s, 13.1914043663353 MB/s).\n",
      "Processed 6000000 documents (200050.55910611257 docs/s, 13.943962160274657 MB/s).\n",
      "Processed 6000000 documents (198461.68328781088 docs/s, 13.834771772633495 MB/s).\n",
      "Processed 7000000 documents (204207.6468335955 docs/s, 14.363448242524736 MB/s).\n",
      "Processed 7000000 documents (203042.82692584555 docs/s, 14.278425743903558 MB/s).\n",
      "Processed 8000000 documents (203826.78433157504 docs/s, 14.355589780703452 MB/s).\n",
      "Processed 8000000 documents (203038.40759621322 docs/s, 14.297952382751262 MB/s).\n",
      "Processed 9000000 documents (209362.79240593596 docs/s, 14.742520815642855 MB/s).\n",
      "Processed 9000000 documents (208563.219595517 docs/s, 14.68254917806378 MB/s).\n",
      "Processed 10000000 documents (214462.06473773334 docs/s, 15.133705084268279 MB/s).\n",
      "Processed 10000000 documents (214005.69423081496 docs/s, 15.099612823183662 MB/s).\n",
      "Processed 11000000 documents (217978.3407767568 docs/s, 15.457276672420763 MB/s).\n",
      "Processed 11000000 documents (217777.01608601 docs/s, 15.441211066246861 MB/s).\n",
      "Processed 12000000 documents (216269.54038525466 docs/s, 15.311152891774977 MB/s).\n",
      "Processed 12000000 documents (216205.58722925506 docs/s, 15.308139378543165 MB/s).\n",
      "Processed 13000000 documents (215507.15112966677 docs/s, 15.243264394659006 MB/s).\n",
      "Processed 13000000 documents (215153.50013830152 docs/s, 15.22084539758475 MB/s).\n",
      "Processed 14000000 documents (214766.1500880552 docs/s, 15.17379434568837 MB/s).\n",
      "Processed 14000000 documents (214166.7406052961 docs/s, 15.133778777057731 MB/s).\n",
      "Processed 15000000 documents (213891.48543904023 docs/s, 15.065097212906629 MB/s).\n",
      "Processed 15000000 documents (213079.749847806 docs/s, 15.011206142743852 MB/s).\n",
      "Processed 16000000 documents (213093.5403726073 docs/s, 14.979589233862155 MB/s).\n",
      "Processed 16000000 documents (212268.65393217906 docs/s, 14.924346715157986 MB/s).\n",
      "Processed 17000000 documents (212364.06191548496 docs/s, 14.916026152892925 MB/s).\n",
      "Processed 17000000 documents (211514.83791646935 docs/s, 14.858588269472811 MB/s).\n",
      "Processed 18000000 documents (214939.32170804622 docs/s, 15.184406906070512 MB/s).\n",
      "Processed 18000000 documents (214123.63266456994 docs/s, 15.129542212423331 MB/s).\n",
      "Processed 19000000 documents (217508.71706326402 docs/s, 15.405494481278053 MB/s).\n",
      "Processed 19000000 documents (216511.019976496 docs/s, 15.337935282220363 MB/s).\n",
      "Processed 20000000 documents (217833.78568307648 docs/s, 15.440093415979458 MB/s).\n",
      "Processed 20000000 documents (216946.27198775887 docs/s, 15.381102174458743 MB/s).\n",
      "Processed 21000000 documents (216820.88074837576 docs/s, 15.37641978040985 MB/s).\n",
      "Processed 21000000 documents (216059.2028481895 docs/s, 15.326228671486085 MB/s).\n",
      "Processed 22000000 documents (215877.79168711576 docs/s, 15.291479715632997 MB/s).\n",
      "Processed 22000000 documents (215192.95074436968 docs/s, 15.24645269458411 MB/s).\n",
      "Processed 23000000 documents (214573.91660882282 docs/s, 15.191180048405819 MB/s).\n",
      "Processed 23000000 documents (213949.33596180982 docs/s, 15.150745684212346 MB/s).\n",
      "Processed 24000000 documents (214292.63032029418 docs/s, 15.19576826913597 MB/s).\n",
      "Processed 24000000 documents (213644.55420161874 docs/s, 15.154130334344774 MB/s).\n",
      "Processed 25000000 documents (215859.75188171337 docs/s, 15.35335044884118 MB/s).\n",
      "Processed 25000000 documents (215116.79564567053 docs/s, 15.30422472920379 MB/s).\n",
      "Processed 26000000 documents (216177.34960198766 docs/s, 15.409257544848296 MB/s).\n",
      "Processed 26000000 documents (215445.06465966435 docs/s, 15.360327527362424 MB/s).\n",
      "Processed 27000000 documents (217799.1791286603 docs/s, 15.584023095017429 MB/s).\n",
      "Processed 27000000 documents (216867.6467987764 docs/s, 15.523969047444535 MB/s).\n",
      "Processed 28000000 documents (219229.92680347126 docs/s, 15.683769907680896 MB/s).\n",
      "Processed 28000000 documents (218078.94905598057 docs/s, 15.607993849576518 MB/s).\n",
      "Processed 29000000 documents (218911.11508321858 docs/s, 15.647412425761399 MB/s).\n",
      "Processed 29000000 documents (217484.40709896284 docs/s, 15.551166840073053 MB/s).\n",
      "Processed 30000000 documents (218289.57029963983 docs/s, 15.579525617726636 MB/s).\n",
      "Processed 30000000 documents (216917.9889374155 docs/s, 15.487283718448204 MB/s).\n",
      "Processed 31000000 documents (217653.45724364417 docs/s, 15.507300903566659 MB/s).\n",
      "Processed 31000000 documents (216320.09554594694 docs/s, 15.418629168736956 MB/s).\n",
      "Processed 32000000 documents (217115.99246515488 docs/s, 15.428533936293405 MB/s).\n",
      "Processed 32000000 documents (215770.5191173537 docs/s, 15.339668865130358 MB/s).\n",
      "Processed 33000000 documents (217132.3870723286 docs/s, 15.414061608858061 MB/s).\n",
      "Processed 33000000 documents (215734.97963592847 docs/s, 15.32079674482594 MB/s).\n",
      "Processed 34000000 documents (218718.5000305088 docs/s, 15.518392396340412 MB/s).\n",
      "Processed 34000000 documents (217179.57214847885 docs/s, 15.414971226333014 MB/s).\n",
      "Processed 35000000 documents (218409.84864749986 docs/s, 15.48688203510696 MB/s).\n",
      "Processed 35000000 documents (216794.21654978066 docs/s, 15.377979587043876 MB/s).\n",
      "Processed 36000000 documents (218092.49343413813 docs/s, 15.463818625355433 MB/s).\n",
      "Processed 36000000 documents (216449.46752400632 docs/s, 15.352697167859553 MB/s).\n",
      "Processed 37000000 documents (217801.5468748097 docs/s, 15.438416647527948 MB/s).\n",
      "Processed 37000000 documents (214733.24163690122 docs/s, 15.226260396249439 MB/s).\n",
      "Opening bookcorpus_ss_0.jsonl\n",
      "Opening bookcorpus_ss_1.jsonl\n",
      "Time to startup: 0.05505990982055664\n",
      "Time to startup: 0.05496358871459961\n",
      "Processed 1000000 documents (63902.19948561696 docs/s, 4.8118964534579725 MB/s).\n",
      "Processed 1000000 documents (62395.209418714716 docs/s, 4.699753595464171 MB/s).\n",
      "Processed 2000000 documents (68189.37926597275 docs/s, 4.8888937770117735 MB/s).\n",
      "Processed 2000000 documents (65887.01306208827 docs/s, 4.724995130306709 MB/s).\n",
      "Processed 3000000 documents (69350.96784491201 docs/s, 4.980340651602728 MB/s).\n",
      "Processed 3000000 documents (67390.5276522948 docs/s, 4.84123613612157 MB/s).\n",
      "Processed 4000000 documents (70199.33056048781 docs/s, 5.024996347188021 MB/s).\n",
      "Processed 4000000 documents (67106.39421626726 docs/s, 4.804823771265922 MB/s).\n",
      "Processed 5000000 documents (70221.52300301241 docs/s, 4.961452949379339 MB/s).\n",
      "Processed 5000000 documents (67362.14198937954 docs/s, 4.760574020943521 MB/s).\n",
      "Processed 6000000 documents (69450.41301041463 docs/s, 4.973625719022814 MB/s).\n",
      "Processed 6000000 documents (66973.15798662504 docs/s, 4.796737824995902 MB/s).\n",
      "Processed 7000000 documents (68919.49750468845 docs/s, 4.979414943809587 MB/s).\n",
      "Processed 7000000 documents (66781.82402015688 docs/s, 4.823944256581073 MB/s).\n",
      "Processed 8000000 documents (68609.03569325939 docs/s, 4.963355419485015 MB/s).\n",
      "Processed 8000000 documents (66665.22651710526 docs/s, 4.8220366914968755 MB/s).\n",
      "Processed 9000000 documents (68301.59193272385 docs/s, 4.940152278748583 MB/s).\n",
      "Processed 9000000 documents (66909.80536634749 docs/s, 4.838305483263663 MB/s).\n",
      "Processed 10000000 documents (67828.06812210429 docs/s, 4.916059544341748 MB/s).\n",
      "Processed 10000000 documents (67130.49301521435 docs/s, 4.864906558557766 MB/s).\n",
      "Processed 11000000 documents (67716.86988914783 docs/s, 4.931445024694304 MB/s).\n",
      "Processed 11000000 documents (66974.76143371408 docs/s, 4.876848407143752 MB/s).\n",
      "Processed 12000000 documents (67990.23060601717 docs/s, 4.943997136598672 MB/s).\n",
      "Processed 12000000 documents (66334.7046524609 docs/s, 4.82314811967428 MB/s).\n",
      "Processed 13000000 documents (68027.03311289429 docs/s, 4.942664919311323 MB/s).\n",
      "Processed 13000000 documents (65954.76096716686 docs/s, 4.791302907209823 MB/s).\n",
      "Processed 14000000 documents (68270.37496333128 docs/s, 4.954842355078722 MB/s).\n",
      "Processed 14000000 documents (66061.83198062159 docs/s, 4.793832075744816 MB/s).\n",
      "Processed 15000000 documents (68448.034424653 docs/s, 4.9530337788282575 MB/s).\n",
      "Processed 15000000 documents (65772.82244666172 docs/s, 4.758434671023587 MB/s).\n",
      "Processed 16000000 documents (68450.08049002821 docs/s, 4.943600142568703 MB/s).\n",
      "Processed 16000000 documents (65630.55690439831 docs/s, 4.739118756739795 MB/s).\n",
      "Processed 17000000 documents (68350.64520578476 docs/s, 4.932285711289156 MB/s).\n",
      "Processed 17000000 documents (65811.7580409313 docs/s, 4.748388250279225 MB/s).\n",
      "Processed 18000000 documents (67834.18229052807 docs/s, 4.922807887641154 MB/s).\n",
      "Processed 18000000 documents (65768.98233809792 docs/s, 4.772087796447226 MB/s).\n",
      "Processed 19000000 documents (67446.0833413499 docs/s, 4.9070114286233455 MB/s).\n",
      "Processed 19000000 documents (65954.89548757322 docs/s, 4.797575294186087 MB/s).\n",
      "Processed 20000000 documents (67485.76204712904 docs/s, 4.913741270492988 MB/s).\n",
      "Processed 20000000 documents (65756.01175543541 docs/s, 4.78660950763814 MB/s).\n",
      "Processed 21000000 documents (67495.44277286016 docs/s, 4.91695995631844 MB/s).\n",
      "Processed 21000000 documents (65440.69590022106 docs/s, 4.766116851438808 MB/s).\n",
      "Processed 22000000 documents (67744.91385214873 docs/s, 4.929357617391981 MB/s).\n",
      "Processed 22000000 documents (65618.55998590135 docs/s, 4.773575018515377 MB/s).\n",
      "Processed 23000000 documents (67798.88320740368 docs/s, 4.930875489646918 MB/s).\n",
      "Processed 23000000 documents (65908.98003740975 docs/s, 4.792261429034608 MB/s).\n",
      "Processed 24000000 documents (67821.07974425772 docs/s, 4.940411892592239 MB/s).\n",
      "Processed 24000000 documents (65963.19521664148 docs/s, 4.803740898932599 MB/s).\n",
      "Processed 25000000 documents (67892.53213846787 docs/s, 4.960028367529576 MB/s).\n",
      "Processed 25000000 documents (66010.39355357531 docs/s, 4.821383225745943 MB/s).\n",
      "Processed 26000000 documents (67748.29311093589 docs/s, 4.959798090078562 MB/s).\n",
      "Processed 26000000 documents (66065.875718366 docs/s, 4.8356284641912515 MB/s).\n",
      "Processed 27000000 documents (67494.4889932524 docs/s, 4.960593663570413 MB/s).\n",
      "Processed 27000000 documents (65894.46462918152 docs/s, 4.840993723591993 MB/s).\n",
      "Processed 28000000 documents (67392.40201195788 docs/s, 4.952258235807119 MB/s).\n",
      "Processed 28000000 documents (66006.32901826689 docs/s, 4.8484178394907635 MB/s).\n",
      "Processed 29000000 documents (67320.52656972938 docs/s, 4.94255560969494 MB/s).\n",
      "Processed 29000000 documents (66039.81257074184 docs/s, 4.846787550203153 MB/s).\n",
      "Processed 30000000 documents (67180.14152105388 docs/s, 4.92500425632926 MB/s).\n",
      "Processed 30000000 documents (66201.24190178885 docs/s, 4.851517152594204 MB/s).\n",
      "Processed 31000000 documents (66979.13980455302 docs/s, 4.902221190212687 MB/s).\n",
      "Processed 31000000 documents (66266.21936851986 docs/s, 4.848104824490551 MB/s).\n",
      "Processed 32000000 documents (66917.6771516235 docs/s, 4.885377155182982 MB/s).\n",
      "Processed 32000000 documents (66389.19644672734 docs/s, 4.84471993764003 MB/s).\n",
      "Processed 33000000 documents (66794.94134517123 docs/s, 4.8713506201318815 MB/s).\n",
      "Processed 33000000 documents (66560.44091712532 docs/s, 4.852417010460531 MB/s).\n",
      "Processed 34000000 documents (66702.33692400678 docs/s, 4.8620094715439475 MB/s).\n",
      "Processed 34000000 documents (66663.67285591345 docs/s, 4.857420646389608 MB/s).\n",
      "Processed 35000000 documents (66809.04859829978 docs/s, 4.865075435253809 MB/s).\n",
      "Processed 35000000 documents (66485.15859701629 docs/s, 4.843225295021567 MB/s).\n",
      "Processed 36000000 documents (66918.05584822537 docs/s, 4.8728421833452655 MB/s).\n",
      "Processed 36000000 documents (66300.97241847217 docs/s, 4.829555325832411 MB/s).\n",
      "Processed 37000000 documents (66973.5004335747 docs/s, 4.875416674378648 MB/s).\n",
      "Processed 37000000 documents (66197.18285767651 docs/s, 4.820548951357726 MB/s).\n",
      "INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from output/bookcorpus_0_text_sentence.idx\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the sequence lengths\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the sequence pointers\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the document indices\n",
      "INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 37078626\n",
      "INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 37002114\n",
      "INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from output/bookcorpus_1_text_sentence.idx\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the sequence lengths\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the sequence pointers\n",
      "INFO:megatron.core.datasets.indexed_dataset:\tExtract the document indices\n",
      "INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 37078465\n",
      "INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 37002114\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p output\n",
    "!python Megatron-LM/tools/preprocess_data.py \\\n",
    "    --input bookcorpus.jsonl \\\n",
    "    --json-keys text \\\n",
    "    --output-prefix output/bookcorpus \\\n",
    "    --tokenizer-type GPT2BPETokenizer \\\n",
    "    --vocab-file vocab.json \\\n",
    "    --merge-file merges.txt \\\n",
    "    --workers 4 \\\n",
    "    --append-eod \\\n",
    "    --partitions 2 \\\n",
    "    --log-interval 1000000 \\\n",
    "    --split-sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f870f2-6b6b-48d2-a966-c24486040e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bookcorpus_0_text_sentence.bin\tbookcorpus_1_text_sentence.idx\n",
      "bookcorpus_0_text_sentence.idx\tbookcorpus_text_sentence.bin\n",
      "bookcorpus_1_text_sentence.bin\tbookcorpus_text_sentence.idx\n"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "!ls output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbcafd3-94ad-419d-8a62-56fad50e10bd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ca1b84-8697-43a0-bd20-804025aa8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TOKENIZER_MODEL=\"meta-llama/Llama-3.1-8B\"\n",
    "!export DATA_PATH=\"output/bookcorpus_text_sentence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f077878-7951-4173-bcc2-aa92601885ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples/llama/train_llama3.sh: line 31: export: --: invalid option\n",
      "export: usage: export [-fn] [name[=value] ...] or export -p\n",
      "NO_TRAINING=0\n",
      "Single node setup, skipping NCCL and GLOO socket interface settings.\n",
      "experiment/1nodes_rank0_train_8B_mbs2_bs64_tp1_pp1_cp1_iter10/TE_FP8_0/2025-10-09_13-36-02/output_perf.log\n",
      "[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:290: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias, allreduce_dgrad):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:301: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:393: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:433: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\n",
      "  warnings.warn(\"Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\", UserWarning)\n",
      "/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0\n",
      "  warnings.warn(self.msg)\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron plugin due to: ImportError(\"cannot import name 'get_tensor_model_parallel_group_if_none' from 'megatron.core.utils' (/shared-docker/Megatron-LM/megatron/core/utils.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron_eagle plugin due to: ImportError(\"cannot import name 'get_expert_tensor_parallel_world_size' from 'megatron.core.parallel_state' (/shared-docker/Megatron-LM/megatron/core/parallel_state.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "using world size: 1, data-parallel size: 1, context-parallel size: 1, tensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0\n",
      "WARNING: overriding default arguments for tokenizer_type:GPT2BPETokenizer                        with tokenizer_type:HuggingFaceTokenizer\n",
      "accumulate and all-reduce gradients in fp32 for bfloat16 data type.\n",
      "using torch.bfloat16 for parameters ...\n",
      "------------------------ arguments ------------------------\n",
      "  accumulate_allreduce_grads_in_fp32 .............. True\n",
      "  adam_beta1 ...................................... 0.9\n",
      "  adam_beta2 ...................................... 0.999\n",
      "  adam_eps ........................................ 1e-08\n",
      "  add_bias_linear ................................. False\n",
      "  add_position_embedding .......................... False\n",
      "  add_qkv_bias .................................... False\n",
      "  adlr_autoresume ................................. False\n",
      "  adlr_autoresume_interval ........................ 1000\n",
      "  align_grad_reduce ............................... True\n",
      "  align_param_gather .............................. False\n",
      "  app_tag_run_name ................................ None\n",
      "  app_tag_run_version ............................. 0.0.0\n",
      "  apply_layernorm_1p .............................. False\n",
      "  apply_query_key_layer_scaling ................... False\n",
      "  apply_residual_connection_post_layernorm ........ False\n",
      "  apply_rope_fusion ............................... True\n",
      "  async_save ...................................... None\n",
      "  async_tensor_model_parallel_allreduce ........... False\n",
      "  attention_dropout ............................... 0.0\n",
      "  attention_softmax_in_fp32 ....................... False\n",
      "  auto_detect_ckpt_format ......................... False\n",
      "  barrier_with_L1_time ............................ True\n",
      "  bert_binary_head ................................ True\n",
      "  bert_embedder_type .............................. megatron\n",
      "  bert_load ....................................... None\n",
      "  bf16 ............................................ True\n",
      "  bias_dropout_fusion ............................. True\n",
      "  bias_gelu_fusion ................................ False\n",
      "  bias_swiglu_fusion .............................. True\n",
      "  biencoder_projection_dim ........................ 0\n",
      "  biencoder_shared_query_context_model ............ False\n",
      "  block_data_path ................................. None\n",
      "  calculate_per_token_loss ........................ False\n",
      "  check_for_nan_in_loss_and_grad .................. True\n",
      "  check_weight_hash_across_dp_replicas_interval ... None\n",
      "  ckpt_assume_constant_structure .................. False\n",
      "  ckpt_convert_format ............................. None\n",
      "  ckpt_convert_save ............................... None\n",
      "  ckpt_convert_update_legacy_dist_opt_format ...... False\n",
      "  ckpt_format ..................................... torch_dist\n",
      "  ckpt_fully_parallel_load ........................ False\n",
      "  ckpt_fully_parallel_save ........................ True\n",
      "  ckpt_fully_parallel_save_deprecated ............. False\n",
      "  ckpt_step ....................................... None\n",
      "  classes_fraction ................................ 1.0\n",
      "  clip_grad ....................................... 1.0\n",
      "  clone_scatter_output_in_embedding ............... True\n",
      "  config_logger_dir ............................... \n",
      "  consumed_train_samples .......................... 0\n",
      "  consumed_valid_samples .......................... 0\n",
      "  context_parallel_size ........................... 1\n",
      "  create_attention_mask_in_dataloader ............. True\n",
      "  cross_entropy_loss_fusion ....................... False\n",
      "  data_cache_path ................................. None\n",
      "  data_parallel_random_init ....................... False\n",
      "  data_parallel_size .............................. 1\n",
      "  data_path ....................................... None\n",
      "  data_per_class_fraction ......................... 1.0\n",
      "  data_sharding ................................... True\n",
      "  dataloader_type ................................. cyclic\n",
      "  ddp_average_in_collective ....................... False\n",
      "  ddp_bucket_size ................................. None\n",
      "  decoder_first_pipeline_num_layers ............... None\n",
      "  decoder_last_pipeline_num_layers ................ None\n",
      "  decoder_num_layers .............................. None\n",
      "  decoder_seq_length .............................. None\n",
      "  decoupled_lr .................................... None\n",
      "  decoupled_min_lr ................................ None\n",
      "  decrease_batch_size_if_needed ................... False\n",
      "  defer_embedding_wgrad_compute ................... False\n",
      "  deprecated_use_mcore_models ..................... True\n",
      "  deterministic_mode .............................. False\n",
      "  dino_bottleneck_size ............................ 256\n",
      "  dino_freeze_last_layer .......................... 1\n",
      "  dino_head_hidden_size ........................... 2048\n",
      "  dino_local_crops_number ......................... 10\n",
      "  dino_local_img_size ............................. 96\n",
      "  dino_norm_last_layer ............................ False\n",
      "  dino_teacher_temp ............................... 0.07\n",
      "  dino_warmup_teacher_temp ........................ 0.04\n",
      "  dino_warmup_teacher_temp_epochs ................. 30\n",
      "  disable_straggler_on_startup .................... False\n",
      "  disable_te_fused_rope ........................... False\n",
      "  dist_ckpt_format_deprecated ..................... None\n",
      "  dist_ckpt_strictness ............................ assume_ok_unexpected\n",
      "  distribute_saved_activations .................... False\n",
      "  distributed_backend ............................. nccl\n",
      "  distributed_timeout_minutes ..................... 120\n",
      "  embedding_path .................................. None\n",
      "  empty_unused_memory_level ....................... 0\n",
      "  enable_ft_package ............................... False\n",
      "  enable_one_logger ............................... True\n",
      "  encoder_num_layers .............................. 32\n",
      "  encoder_pipeline_model_parallel_size ............ 0\n",
      "  encoder_seq_length .............................. 4096\n",
      "  encoder_tensor_model_parallel_size .............. 0\n",
      "  end_weight_decay ................................ 0.1\n",
      "  eod_mask_loss ................................... False\n",
      "  eval_interval ................................... 320000\n",
      "  eval_iters ...................................... -1\n",
      "  evidence_data_path .............................. None\n",
      "  exit_duration_in_mins ........................... None\n",
      "  exit_interval ................................... None\n",
      "  exit_on_missing_checkpoint ...................... False\n",
      "  exit_signal_handler ............................. False\n",
      "  expert_model_parallel_size ...................... 1\n",
      "  ffn_hidden_size ................................. 14336\n",
      "  finetune ........................................ False\n",
      "  fp16 ............................................ False\n",
      "  fp16_lm_cross_entropy ........................... False\n",
      "  fp32_residual_connection ........................ False\n",
      "  fp8 ............................................. None\n",
      "  fp8_amax_compute_algo ........................... most_recent\n",
      "  fp8_amax_history_len ............................ 1\n",
      "  fp8_interval .................................... 1\n",
      "  fp8_margin ...................................... 0\n",
      "  fp8_param_gather ................................ False\n",
      "  fp8_wgrad ....................................... True\n",
      "  global_batch_size ............................... 64\n",
      "  gradient_accumulation_fusion .................... False\n",
      "  group_query_attention ........................... True\n",
      "  head_lr_mult .................................... 1.0\n",
      "  hidden_dropout .................................. 0.0\n",
      "  hidden_size ..................................... 4096\n",
      "  hybrid_attention_ratio .......................... 0.0\n",
      "  hybrid_mlp_ratio ................................ 0.0\n",
      "  hybrid_override_pattern ......................... None\n",
      "  hysteresis ...................................... 2\n",
      "  ict_head_size ................................... None\n",
      "  ict_load ........................................ None\n",
      "  img_h ........................................... 224\n",
      "  img_w ........................................... 224\n",
      "  indexer_batch_size .............................. 128\n",
      "  indexer_log_interval ............................ 1000\n",
      "  inference_batch_times_seqlen_threshold .......... 512\n",
      "  init_method_std ................................. 0.02\n",
      "  init_method_xavier_uniform ...................... False\n",
      "  initial_loss_scale .............................. 4294967296\n",
      "  iter_per_epoch .................................. 1250\n",
      "  kv_channels ..................................... 128\n",
      "  kv_lora_rank .................................... 32\n",
      "  lazy_mpu_init ................................... None\n",
      "  load ............................................ None\n",
      "  local_rank ...................................... 0\n",
      "  log_interval .................................... 1\n",
      "  log_loss_scale_to_tensorboard ................... True\n",
      "  log_memory_to_tensorboard ....................... False\n",
      "  log_num_zeros_in_grad ........................... False\n",
      "  log_params_norm ................................. False\n",
      "  log_progress .................................... False\n",
      "  log_straggler ................................... False\n",
      "  log_throughput .................................. True\n",
      "  log_timers_to_tensorboard ....................... False\n",
      "  log_validation_ppl_to_tensorboard ............... False\n",
      "  log_world_size_to_tensorboard ................... False\n",
      "  logging_level ................................... None\n",
      "  loss_scale ...................................... None\n",
      "  loss_scale_window ............................... 1000\n",
      "  lr .............................................. 0.0001\n",
      "  lr_decay_iters .................................. 320000\n",
      "  lr_decay_samples ................................ None\n",
      "  lr_decay_style .................................. cosine\n",
      "  lr_warmup_fraction .............................. None\n",
      "  lr_warmup_init .................................. 0.0\n",
      "  lr_warmup_iters ................................. 0\n",
      "  lr_warmup_samples ............................... 0\n",
      "  lr_wsd_decay_iters .............................. None\n",
      "  lr_wsd_decay_samples ............................ None\n",
      "  lr_wsd_decay_style .............................. exponential\n",
      "  make_vocab_size_divisible_by .................... 128\n",
      "  manual_gc ....................................... False\n",
      "  manual_gc_eval .................................. True\n",
      "  manual_gc_interval .............................. 0\n",
      "  mask_factor ..................................... 1.0\n",
      "  mask_prob ....................................... 0.15\n",
      "  mask_type ....................................... random\n",
      "  masked_softmax_fusion ........................... False\n",
      "  max_position_embeddings ......................... 128000\n",
      "  max_tokens_to_oom ............................... 12000\n",
      "  merge_file ...................................... None\n",
      "  micro_batch_size ................................ 2\n",
      "  min_loss_scale .................................. 1.0\n",
      "  min_lr .......................................... 1e-05\n",
      "  mmap_bin_files .................................. True\n",
      "  mock_data ....................................... True\n",
      "  moe_aux_loss_coeff .............................. 0.0\n",
      "  moe_expert_capacity_factor ...................... None\n",
      "  moe_extended_tp ................................. False\n",
      "  moe_grouped_gemm ................................ False\n",
      "  moe_input_jitter_eps ............................ None\n",
      "  moe_layer_recompute ............................. False\n",
      "  moe_pad_expert_input_to_capacity ................ False\n",
      "  moe_per_layer_logging ........................... False\n",
      "  moe_router_load_balancing_type .................. aux_loss\n",
      "  moe_router_pre_softmax .......................... False\n",
      "  moe_router_topk ................................. 2\n",
      "  moe_shared_expert_intermediate_size ............. None\n",
      "  moe_shared_expert_overlap ....................... False\n",
      "  moe_token_dispatcher_type ....................... allgather\n",
      "  moe_token_drop_policy ........................... probs\n",
      "  moe_use_upcycling ............................... False\n",
      "  moe_z_loss_coeff ................................ None\n",
      "  multi_latent_attention .......................... False\n",
      "  nccl_communicator_config_path ................... None\n",
      "  no_load_optim ................................... None\n",
      "  no_load_rng ..................................... None\n",
      "  no_persist_layer_norm ........................... False\n",
      "  no_save_optim ................................... True\n",
      "  no_save_rng ..................................... None\n",
      "  non_persistent_ckpt_type ........................ None\n",
      "  non_persistent_global_ckpt_dir .................. None\n",
      "  non_persistent_local_ckpt_algo .................. fully_parallel\n",
      "  non_persistent_local_ckpt_dir ................... None\n",
      "  non_persistent_save_interval .................... None\n",
      "  norm_epsilon .................................... 1e-05\n",
      "  normalization ................................... RMSNorm\n",
      "  num_attention_heads ............................. 32\n",
      "  num_channels .................................... 3\n",
      "  num_classes ..................................... 1000\n",
      "  num_dataset_builder_threads ..................... 1\n",
      "  num_experts ..................................... None\n",
      "  num_layers ...................................... 32\n",
      "  num_layers_per_virtual_pipeline_stage ........... None\n",
      "  num_query_groups ................................ 8\n",
      "  num_workers ..................................... 8\n",
      "  one_logger_async ................................ False\n",
      "  one_logger_project .............................. megatron-lm\n",
      "  one_logger_run_name ............................. None\n",
      "  onnx_safe ....................................... None\n",
      "  openai_gelu ..................................... False\n",
      "  optimizer ....................................... adam\n",
      "  output_bert_embeddings .......................... False\n",
      "  overlap_grad_reduce ............................. True\n",
      "  overlap_p2p_comm ................................ False\n",
      "  overlap_param_gather ............................ True\n",
      "  overlap_param_gather_with_optimizer_step ........ False\n",
      "  override_opt_param_scheduler .................... False\n",
      "  params_dtype .................................... torch.bfloat16\n",
      "  patch_dim ....................................... 16\n",
      "  perform_initialization .......................... True\n",
      "  pipeline_model_parallel_size .................... 1\n",
      "  pipeline_model_parallel_split_rank .............. None\n",
      "  position_embedding_type ......................... rope\n",
      "  pretrained_checkpoint ........................... None\n",
      "  profile ......................................... False\n",
      "  profile_ranks ................................... [0]\n",
      "  profile_step_end ................................ 12\n",
      "  profile_step_start .............................. 10\n",
      "  q_lora_rank ..................................... None\n",
      "  qk_head_dim ..................................... 128\n",
      "  qk_layernorm .................................... False\n",
      "  qk_pos_emb_head_dim ............................. 64\n",
      "  query_in_block_prob ............................. 0.1\n",
      "  rampup_batch_size ............................... None\n",
      "  rank ............................................ 0\n",
      "  recompute_granularity ........................... None\n",
      "  recompute_method ................................ None\n",
      "  recompute_num_layers ............................ None\n",
      "  renormalize_blend_weights ....................... False\n",
      "  reset_attention_mask ............................ False\n",
      "  reset_position_ids .............................. False\n",
      "  retriever_report_topk_accuracies ................ []\n",
      "  retriever_score_scaling ......................... False\n",
      "  retriever_seq_length ............................ 256\n",
      "  retro_add_retriever ............................. False\n",
      "  retro_attention_gate ............................ 1\n",
      "  retro_cyclic_train_iters ........................ None\n",
      "  retro_encoder_attention_dropout ................. 0.1\n",
      "  retro_encoder_hidden_dropout .................... 0.1\n",
      "  retro_encoder_layers ............................ 2\n",
      "  retro_num_neighbors ............................. 2\n",
      "  retro_num_retrieved_chunks ...................... 2\n",
      "  retro_project_dir ............................... None\n",
      "  retro_verify_neighbor_count ..................... True\n",
      "  rotary_base ..................................... 10000\n",
      "  rotary_interleaved .............................. False\n",
      "  rotary_percent .................................. 1.0\n",
      "  rotary_scaling_factor ........................... 1.0\n",
      "  rotary_seq_len_interpolation_factor ............. None\n",
      "  s3_cache_path ................................... None\n",
      "  sample_rate ..................................... 1.0\n",
      "  save ............................................ None\n",
      "  save_interval ................................... 5000\n",
      "  scatter_gather_tensors_in_pipeline .............. True\n",
      "  seed ............................................ 1234\n",
      "  seq_length ...................................... 4096\n",
      "  sequence_parallel ............................... False\n",
      "  sgd_momentum .................................... 0.9\n",
      "  short_seq_prob .................................. 0.1\n",
      "  skip_train ...................................... False\n",
      "  skipped_train_samples ........................... 0\n",
      "  spec ............................................ None\n",
      "  split ........................................... None\n",
      "  squared_relu .................................... False\n",
      "  standalone_embedding_stage ...................... False\n",
      "  start_weight_decay .............................. 0.1\n",
      "  straggler_ctrlr_port ............................ 65535\n",
      "  straggler_minmax_count .......................... 1\n",
      "  swiglu .......................................... True\n",
      "  swin_backbone_type .............................. tiny\n",
      "  tensor_model_parallel_size ...................... 1\n",
      "  tensorboard_dir ................................. experiment/1nodes_rank0_train_8B_mbs2_bs64_tp1_pp1_cp1_iter10/TE_FP8_0/2025-10-09_13-36-02\n",
      "  tensorboard_log_interval ........................ 1\n",
      "  tensorboard_queue_size .......................... 1000\n",
      "  test_data_path .................................. None\n",
      "  test_mode ....................................... False\n",
      "  tiktoken_num_special_tokens ..................... 1000\n",
      "  tiktoken_pattern ................................ None\n",
      "  tiktoken_special_tokens ......................... None\n",
      "  timing_log_level ................................ 0\n",
      "  timing_log_option ............................... minmax\n",
      "  titles_data_path ................................ None\n",
      "  tokenizer_model ................................. meta-llama/Llama-3.1-8B\n",
      "  tokenizer_type .................................. HuggingFaceTokenizer\n",
      "  tp_comm_bootstrap_backend ....................... nccl\n",
      "  tp_comm_bulk_dgrad .............................. True\n",
      "  tp_comm_bulk_wgrad .............................. True\n",
      "  tp_comm_overlap ................................. False\n",
      "  tp_comm_overlap_ag .............................. True\n",
      "  tp_comm_overlap_cfg ............................. None\n",
      "  tp_comm_overlap_rs .............................. True\n",
      "  tp_comm_overlap_rs_dgrad ........................ False\n",
      "  tp_comm_split_ag ................................ True\n",
      "  tp_comm_split_rs ................................ True\n",
      "  train_data_path ................................. None\n",
      "  train_iters ..................................... 10\n",
      "  train_samples ................................... None\n",
      "  train_sync_interval ............................. None\n",
      "  transformer_impl ................................ transformer_engine\n",
      "  transformer_pipeline_model_parallel_size ........ 1\n",
      "  untie_embeddings_and_output_weights ............. True\n",
      "  use_checkpoint_args ............................. False\n",
      "  use_checkpoint_opt_param_scheduler .............. False\n",
      "  use_cpu_initialization .......................... None\n",
      "  use_dist_ckpt ................................... True\n",
      "  use_dist_ckpt_deprecated ........................ False\n",
      "  use_distributed_optimizer ....................... True\n",
      "  use_flash_attn .................................. True\n",
      "  use_legacy_models ............................... False\n",
      "  use_one_sent_docs ............................... False\n",
      "  use_pytorch_profiler ............................ False\n",
      "  use_ring_exchange_p2p ........................... False\n",
      "  use_rope_scaling ................................ False\n",
      "  use_rotary_position_embeddings .................. False\n",
      "  use_tp_pp_dp_mapping ............................ False\n",
      "  v_head_dim ...................................... 128\n",
      "  valid_data_path ................................. None\n",
      "  variable_seq_lengths ............................ False\n",
      "  virtual_pipeline_model_parallel_size ............ None\n",
      "  vision_backbone_type ............................ vit\n",
      "  vision_pretraining .............................. False\n",
      "  vision_pretraining_type ......................... classify\n",
      "  vocab_extra_ids ................................. 0\n",
      "  vocab_file ...................................... None\n",
      "  vocab_size ...................................... None\n",
      "  wandb_exp_name .................................. \n",
      "  wandb_project ................................... \n",
      "  wandb_save_dir .................................. \n",
      "  weight_decay .................................... 0.1\n",
      "  weight_decay_incr_style ......................... constant\n",
      "  wgrad_deferral_limit ............................ 0\n",
      "  world_size ...................................... 1\n",
      "  yaml_cfg ........................................ None\n",
      "-------------------- end of arguments ---------------------\n",
      "INFO:megatron.core.num_microbatches_calculator:setting number of microbatches to constant 32\n",
      "> building HuggingFaceTokenizer tokenizer ...\n",
      " > padded vocab (size: 128256) with 0 dummy tokens (new size: 128256)\n",
      "> setting tensorboard ...\n",
      "WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it\n",
      "> initializing torch distributed ...\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "> initialized tensor model parallel with size 1\n",
      "> initialized pipeline model parallel with size 1\n",
      "> setting random seeds to 1234 ...\n",
      "> compiling dataset index builder ...\n",
      "make: Entering directory '/shared-docker/Megatron-LM/megatron/core/datasets'\n",
      "make: Nothing to be done for 'default'.\n",
      "make: Leaving directory '/shared-docker/Megatron-LM/megatron/core/datasets'\n",
      ">>> done with dataset index builder. Compilation time: 0.020 seconds\n",
      "WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.\n",
      "> compiling and loading fused kernels ...\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank0]:[W1009 13:36:10.371877899 ProcessGroupNCCL.cpp:5059] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.\n",
      ">>> done with compiling and loading fused kernels. Compilation time: 1.823 seconds\n",
      "[rank0]:[W1009 13:36:12.194262091 init.cpp:772] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())\n",
      "time to initialize megatron (seconds): 3.397\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[after megatron is initialized] datetime: 2025-10-09 13:36:13 \n",
      "building GPT model ...\n",
      " > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 8030261248\n",
      "INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=False, fp8_param_gather=False)\n",
      "INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 98\n",
      "Params for bucket 1 (525336576 elements):\n",
      "\tmodule.output_layer.weight\n",
      "Params for bucket 2 (58724352 elements):\n",
      "\tmodule.decoder.final_layernorm.weight\n",
      "\tmodule.decoder.layers.31.mlp.linear_fc2.weight\n",
      "Params for bucket 3 (117440512 elements):\n",
      "\tmodule.decoder.layers.31.mlp.linear_fc1.weight\n",
      "Params for bucket 4 (41951232 elements):\n",
      "\tmodule.decoder.layers.31.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.31.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.31.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.31.self_attention.linear_qkv.weight\n",
      "Params for bucket 5 (58720256 elements):\n",
      "\tmodule.decoder.layers.30.mlp.linear_fc2.weight\n",
      "Params for bucket 6 (117440512 elements):\n",
      "\tmodule.decoder.layers.30.mlp.linear_fc1.weight\n",
      "Params for bucket 7 (41951232 elements):\n",
      "\tmodule.decoder.layers.30.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.30.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.30.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.30.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 8 (58720256 elements):\n",
      "\tmodule.decoder.layers.29.mlp.linear_fc2.weight\n",
      "Params for bucket 9 (117440512 elements):\n",
      "\tmodule.decoder.layers.29.mlp.linear_fc1.weight\n",
      "Params for bucket 10 (41951232 elements):\n",
      "\tmodule.decoder.layers.29.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.29.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.29.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.29.self_attention.linear_qkv.weight\n",
      "Params for bucket 11 (58720256 elements):\n",
      "\tmodule.decoder.layers.28.mlp.linear_fc2.weight\n",
      "Params for bucket 12 (117440512 elements):\n",
      "\tmodule.decoder.layers.28.mlp.linear_fc1.weight\n",
      "Params for bucket 13 (41951232 elements):\n",
      "\tmodule.decoder.layers.28.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.28.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.28.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.28.self_attention.linear_proj.weight\n",
      "Params for bucket 14 (58720256 elements):\n",
      "\tmodule.decoder.layers.27.mlp.linear_fc2.weight\n",
      "Params for bucket 15 (117440512 elements):\n",
      "\tmodule.decoder.layers.27.mlp.linear_fc1.weight\n",
      "Params for bucket 16 (41951232 elements):\n",
      "\tmodule.decoder.layers.27.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.27.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.27.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.27.self_attention.linear_proj.weight\n",
      "Params for bucket 17 (58720256 elements):\n",
      "\tmodule.decoder.layers.26.mlp.linear_fc2.weight\n",
      "Params for bucket 18 (117440512 elements):\n",
      "\tmodule.decoder.layers.26.mlp.linear_fc1.weight\n",
      "Params for bucket 19 (41951232 elements):\n",
      "\tmodule.decoder.layers.26.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.26.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.26.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.26.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 20 (58720256 elements):\n",
      "\tmodule.decoder.layers.25.mlp.linear_fc2.weight\n",
      "Params for bucket 21 (117440512 elements):\n",
      "\tmodule.decoder.layers.25.mlp.linear_fc1.weight\n",
      "Params for bucket 22 (41951232 elements):\n",
      "\tmodule.decoder.layers.25.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.25.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.25.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.25.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 23 (58720256 elements):\n",
      "\tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "Params for bucket 24 (117440512 elements):\n",
      "\tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "Params for bucket 25 (41951232 elements):\n",
      "\tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "Params for bucket 26 (58720256 elements):\n",
      "\tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "Params for bucket 27 (117440512 elements):\n",
      "\tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "Params for bucket 28 (41951232 elements):\n",
      "\tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.23.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.23.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.23.self_attention.linear_proj.weight\n",
      "Params for bucket 29 (58720256 elements):\n",
      "\tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "Params for bucket 30 (117440512 elements):\n",
      "\tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "Params for bucket 31 (41951232 elements):\n",
      "\tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.22.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.22.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.22.self_attention.linear_qkv.weight\n",
      "Params for bucket 32 (58720256 elements):\n",
      "\tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "Params for bucket 33 (117440512 elements):\n",
      "\tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "Params for bucket 34 (41951232 elements):\n",
      "\tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.21.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.21.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.21.self_attention.linear_qkv.weight\n",
      "Params for bucket 35 (58720256 elements):\n",
      "\tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "Params for bucket 36 (117440512 elements):\n",
      "\tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "Params for bucket 37 (41951232 elements):\n",
      "\tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.20.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.20.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.20.self_attention.linear_proj.weight\n",
      "Params for bucket 38 (58720256 elements):\n",
      "\tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "Params for bucket 39 (117440512 elements):\n",
      "\tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "Params for bucket 40 (41951232 elements):\n",
      "\tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.19.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.19.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.19.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 41 (58720256 elements):\n",
      "\tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "Params for bucket 42 (117440512 elements):\n",
      "\tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "Params for bucket 43 (41951232 elements):\n",
      "\tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.18.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.18.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.18.self_attention.linear_proj.weight\n",
      "Params for bucket 44 (58720256 elements):\n",
      "\tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "Params for bucket 45 (117440512 elements):\n",
      "\tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "Params for bucket 46 (41951232 elements):\n",
      "\tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 47 (58720256 elements):\n",
      "\tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "Params for bucket 48 (117440512 elements):\n",
      "\tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "Params for bucket 49 (41951232 elements):\n",
      "\tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.16.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.16.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.16.self_attention.linear_qkv.weight\n",
      "Params for bucket 50 (58720256 elements):\n",
      "\tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "Params for bucket 51 (117440512 elements):\n",
      "\tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "Params for bucket 52 (41951232 elements):\n",
      "\tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.15.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.15.self_attention.linear_proj.weight\n",
      "Params for bucket 53 (58720256 elements):\n",
      "\tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "Params for bucket 54 (117440512 elements):\n",
      "\tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "Params for bucket 55 (41951232 elements):\n",
      "\tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.14.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.14.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 56 (58720256 elements):\n",
      "\tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "Params for bucket 57 (117440512 elements):\n",
      "\tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "Params for bucket 58 (41951232 elements):\n",
      "\tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.13.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.13.self_attention.linear_qkv.weight\n",
      "Params for bucket 59 (58720256 elements):\n",
      "\tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "Params for bucket 60 (117440512 elements):\n",
      "\tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "Params for bucket 61 (41951232 elements):\n",
      "\tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.12.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.12.self_attention.linear_proj.weight\n",
      "Params for bucket 62 (58720256 elements):\n",
      "\tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "Params for bucket 63 (117440512 elements):\n",
      "\tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "Params for bucket 64 (41951232 elements):\n",
      "\tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.11.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.11.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 65 (58720256 elements):\n",
      "\tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "Params for bucket 66 (117440512 elements):\n",
      "\tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "Params for bucket 67 (41951232 elements):\n",
      "\tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 68 (58720256 elements):\n",
      "\tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "Params for bucket 69 (117440512 elements):\n",
      "\tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "Params for bucket 70 (41951232 elements):\n",
      "\tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.9.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.9.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 71 (58720256 elements):\n",
      "\tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "Params for bucket 72 (117440512 elements):\n",
      "\tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "Params for bucket 73 (41951232 elements):\n",
      "\tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.8.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.8.self_attention.linear_proj.weight\n",
      "Params for bucket 74 (58720256 elements):\n",
      "\tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "Params for bucket 75 (117440512 elements):\n",
      "\tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "Params for bucket 76 (41951232 elements):\n",
      "\tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.7.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.7.self_attention.linear_proj.weight\n",
      "Params for bucket 77 (58720256 elements):\n",
      "\tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "Params for bucket 78 (117440512 elements):\n",
      "\tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "Params for bucket 79 (41951232 elements):\n",
      "\tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.6.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.6.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 80 (58720256 elements):\n",
      "\tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "Params for bucket 81 (117440512 elements):\n",
      "\tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "Params for bucket 82 (41951232 elements):\n",
      "\tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.5.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.5.self_attention.linear_qkv.weight\n",
      "Params for bucket 83 (58720256 elements):\n",
      "\tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "Params for bucket 84 (117440512 elements):\n",
      "\tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "Params for bucket 85 (41951232 elements):\n",
      "\tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.4.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.4.self_attention.linear_qkv.weight\n",
      "Params for bucket 86 (58720256 elements):\n",
      "\tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "Params for bucket 87 (117440512 elements):\n",
      "\tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "Params for bucket 88 (41951232 elements):\n",
      "\tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "Params for bucket 89 (58720256 elements):\n",
      "\tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "Params for bucket 90 (117440512 elements):\n",
      "\tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "Params for bucket 91 (41951232 elements):\n",
      "\tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "Params for bucket 92 (58720256 elements):\n",
      "\tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "Params for bucket 93 (117440512 elements):\n",
      "\tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "Params for bucket 94 (41951232 elements):\n",
      "\tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 95 (58720256 elements):\n",
      "\tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "Params for bucket 96 (117440512 elements):\n",
      "\tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "Params for bucket 97 (41951232 elements):\n",
      "\tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 98 (525336576 elements):\n",
      "\tmodule.embedding.word_embeddings.weight\n",
      "INFO:megatron.core.optimizer:Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0001, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7500de2f2f20>, config_logger_dir='')\n",
      "INFO:megatron.core.optimizer_param_scheduler:> learning rate decay style: cosine\n",
      "[after model, optimizer, and learning rate scheduler are built] datetime: 2025-10-09 13:36:13 \n",
      "> building train, validation, and test datasets ...\n",
      " > datasets target sizes (minimum size):\n",
      "    train:      640\n",
      "    validation: -64\n",
      "    test:       -64\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_config:Let mock = True, as both blend and blend_per_split are None\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split = 1,1,1, an arbitrarily even split, as mock is True\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.3333333333333333), (0.3333333333333333, 0.6666666666666666), (0.6666666666666666, 1.0)]\n",
      "> building train, validation, and test datasets for GPT ...\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=MockGPTDataset, sizes=(640, -64, -64), and config=GPTDatasetConfig(random_seed=1234, sequence_length=4096, blend=None, blend_per_split=[None, None, None], renormalize_blend_weights=False, split='1,1,1', split_matrix=[(0, 0.3333333333333333), (0.3333333333333333, 0.6666666666666666), (0.6666666666666666, 1.0)], num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=True, tokenizer=<megatron.training.tokenizer.tokenizer._HuggingFaceTokenizer object at 0x7500df2cf6a0>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, s3_cache_path=None)\n",
      "INFO:megatron.core.datasets.gpt_dataset:Build and save the MockGPTDataset train indices\n",
      "WARNING:megatron.core.datasets.gpt_dataset:Unable to save the MockGPTDataset indexes because path_to_cache is None\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 16648\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1\n",
      "INFO:megatron.core.datasets.gpt_dataset:Build and save the MockGPTDataset valid indices\n",
      "WARNING:megatron.core.datasets.gpt_dataset:Unable to save the MockGPTDataset indexes because path_to_cache is None\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 16640\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1\n",
      "INFO:megatron.core.datasets.gpt_dataset:Build and save the MockGPTDataset test indices\n",
      "WARNING:megatron.core.datasets.gpt_dataset:Unable to save the MockGPTDataset indexes because path_to_cache is None\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 16671\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1\n",
      "> finished creating GPT datasets ...\n",
      "[after dataloaders are built] datetime: 2025-10-09 13:36:13 \n",
      "done with setup ...\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.\n",
      "  return func(*args, **kwargs)\n",
      "(min, max) time across ranks (ms):\n",
      "    model-and-optimizer-setup ......................: (231.06, 231.06)\n",
      "    train/valid/test-data-iterators-setup ..........: (6.99, 6.99)\n",
      "training ...\n",
      "[before the start of training step] datetime: 2025-10-09 13:36:13 \n",
      "AITER_ASM_DIR set to: /opt/venv/lib/python3.10/site-packages/transformer_engine/aiter/gfx942/\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.\n",
      "  return func(*args, **kwargs)\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:623: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.\n",
      "  warnings.warn(\n",
      "/shared-docker/Megatron-LM/megatron/core/distributed/param_and_grad_buffer.py:259: FutureWarning: `torch.distributed._reduce_scatter_base` is a private function and will be deprecated. Please use `torch.distributed.reduce_scatter_tensor` instead.\n",
      "  torch.distributed._reduce_scatter_base(\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      " [2025-10-09 13:36:56] iteration        1/      10 | consumed samples:           64 | elapsed time per iteration (ms): 42234.4 | throughput per GPU (TFLOP/s/GPU): 319.5 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.258631E+01 | loss scale: 1.0 | grad norm: 13.107 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "Number of parameters in transformer layers in billions:  6.98\n",
      "Number of parameters in embedding layers in billions: 1.05\n",
      "Total number of parameters in billions: 8.03\n",
      "Number of parameters in most loaded shard in billions: 8.0305\n",
      "Theoretical memory footprints: weight and optimizer=137853.14 MB\n",
      "[Rank 0] (after 1 iterations) memory (MB) | allocated: 138033.55859375 | max allocated: 138033.57470703125 | reserved: 149810.0 | max reserved: 149810.0\n",
      " [2025-10-09 13:37:21] iteration        2/      10 | consumed samples:          128 | elapsed time per iteration (ms): 25794.1 | throughput per GPU (TFLOP/s/GPU): 523.1 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 3.872650E+00 | loss scale: 1.0 | grad norm: 11.357 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 13:37:47] iteration        3/      10 | consumed samples:          192 | elapsed time per iteration (ms): 25819.5 | throughput per GPU (TFLOP/s/GPU): 522.6 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 9.157645E-01 | loss scale: 1.0 | grad norm: 3.975 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 13:38:13] iteration        4/      10 | consumed samples:          256 | elapsed time per iteration (ms): 25810.1 | throughput per GPU (TFLOP/s/GPU): 522.8 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 5.759929E-01 | loss scale: 1.0 | grad norm: 10.347 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 13:38:39] iteration        5/      10 | consumed samples:          320 | elapsed time per iteration (ms): 25845.9 | throughput per GPU (TFLOP/s/GPU): 522.0 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 2.549877E-01 | loss scale: 1.0 | grad norm: 1.838 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 13:39:05] iteration        6/      10 | consumed samples:          384 | elapsed time per iteration (ms): 25861.9 | throughput per GPU (TFLOP/s/GPU): 521.7 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.901889E-01 | loss scale: 1.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 13:39:31] iteration        7/      10 | consumed samples:          448 | elapsed time per iteration (ms): 25853.8 | throughput per GPU (TFLOP/s/GPU): 521.9 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.528587E-01 | loss scale: 1.0 | grad norm: 1.269 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 13:39:56] iteration        8/      10 | consumed samples:          512 | elapsed time per iteration (ms): 25875.3 | throughput per GPU (TFLOP/s/GPU): 521.4 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.053610E-01 | loss scale: 1.0 | grad norm: 1.036 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 13:40:22] iteration        9/      10 | consumed samples:          576 | elapsed time per iteration (ms): 25839.0 | throughput per GPU (TFLOP/s/GPU): 522.2 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 8.961845E-02 | loss scale: 1.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-09 13:40:48] iteration       10/      10 | consumed samples:          640 | elapsed time per iteration (ms): 25808.4 | throughput per GPU (TFLOP/s/GPU): 522.8 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 7.795789E-02 | loss scale: 1.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "/shared-docker/Megatron-LM/megatron/core/optimizer/distrib_optimizer.py:557: UserWarning: `DistributedOptimizer.disable_pre_hook` will be deprecated in a future release. Use `DistributedDataParallel.disable_forward_pre_hook` directly.\n",
      "  warnings.warn(\n",
      "[after training is done] datetime: 2025-10-09 13:40:48 \n",
      "[rank0]:[W1009 13:40:49.191782416 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "throughput per GPU: 522.0857142857143\n",
      "elapsed time per iteration: 25843.64285714286\n",
      "tokens/GPU/s: 10143.461642\n"
     ]
    }
   ],
   "source": [
    "!cd Megatron-LM && TEE_OUTPUT=1 MBS=2 BS=64 TP=1 TE_FP8=0 SEQ_LENGTH=4096  \\\n",
    "TOKENIZER_MODEL='meta-llama/Llama-3.1-8B' MODEL_SIZE='8' \\\n",
    "bash examples/llama/train_llama3.sh --data-path ${DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577132d-ca80-42ee-81ba-6065e8dc9c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

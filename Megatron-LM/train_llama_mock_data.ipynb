{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcfe6df9",
   "metadata": {
    "id": "bcfe6df9"
   },
   "source": [
    "# Training Llama-3.1 8B with Megatron-LM\n",
    "\n",
    "This tutorial demonstrates how to train the Llama-3.1 model using *mock data*. The Llama-3.1 8B model is a popular open-source large language model (LLM) designed to handle a wide range of natural language processing tasks efficiently. Learn more about the Llama models at [Llama's website](https://www.llama.com/).\n",
    "\n",
    "This tutorial uses mock data to provide a quick and lightweight demonstration of the training workflow, enabling you to verify that your environment is correctly configured and functional. Mock data is a useful way to validate the training pipeline without requiring large datasets.\n",
    "\n",
    "The training process leverages the Megatron-LM framework, a specialized framework for pretraining and fine-tuning large-scale language models. For more information about Megatron-LM, see their [GitHub repository](https://github.com/NVIDIA/Megatron-LM). All steps are executed within a Docker container, which provides a ready-to-use environment with all necessary dependencies.\n",
    "\n",
    "This tutorial builds on the setup completed in the [Pretraining with Megatron-LM tutorial](https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/pretrain/setup_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WDQ_-T85Kl7m",
   "metadata": {
    "id": "WDQ_-T85Kl7m"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Hugging Face API access\n",
    "\n",
    "* Obtain an API token from [Hugging Face](https://huggingface.co) for downloading models.\n",
    "* Ensure the Hugging Face API token has the necessary permissions and approval to access [Meta's Llama checkpoints](https://huggingface.co/meta-llama/Llama-3.1-8B).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zl7fkZ9uKl7n",
   "metadata": {
    "id": "zl7fkZ9uKl7n"
   },
   "source": [
    "## Prepare the training environment\n",
    "\n",
    "After your system meets the prerequisites, follow these steps to set up the training environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9601ad38",
   "metadata": {
    "id": "9601ad38"
   },
   "source": [
    "### 1. Clone the Megatron-LM repository\n",
    "\n",
    "Run the following commands inside the Docker container to clone the Megatron-LM repository and navigate to the validated commit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88bac989",
   "metadata": {
    "id": "88bac989",
    "tags": [
     "docker"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Megatron-LM'...\n",
      "remote: Enumerating objects: 67721, done.\u001b[K\n",
      "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
      "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
      "remote: Total 67721 (delta 19), reused 9 (delta 4), pack-reused 67663 (from 3)\u001b[K\n",
      "Receiving objects: 100% (67721/67721), 83.25 MiB | 50.77 MiB/s, done.\n",
      "Resolving deltas: 100% (44143/44143), done.\n",
      "Note: switching to 'bb93ccbfeae6363c67b361a97a27c74ab86e7e92'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at bb93ccbfe Merge pull request #39 from ROCm/liz_dev1\n"
     ]
    }
   ],
   "source": [
    "# Clone the Megatron-LM repository and navigate to the validated commit\n",
    "!git clone https://github.com/ROCm/Megatron-LM && cd Megatron-LM && git checkout bb93ccbfeae6363c67b361a97a27c74ab86e7e92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede6ae0-bf25-49f1-84ba-a34848c7fc87",
   "metadata": {
    "id": "9601ad38"
   },
   "source": [
    "### 2. Complete necessary installs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f195f4-0feb-4051-9f95-c71c4a9708bb",
   "metadata": {
    "id": "68f195f4-0feb-4051-9f95-c71c4a9708bb",
    "tags": [
     "docker"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface_hub is already installed.\n",
      "regex is already installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import huggingface_hub\n",
    "    print(\"huggingface_hub is already installed.\")\n",
    "except ImportError:\n",
    "    !pip install huggingface_hub\n",
    "\n",
    "try:\n",
    "    import regex\n",
    "    print(\"regex is already installed.\")\n",
    "except ImportError:\n",
    "    !pip install regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e506c4",
   "metadata": {
    "id": "18e506c4"
   },
   "source": [
    "### 3. Provide your Hugging Face token\n",
    "\n",
    "A Hugging Face token can be generated by signing into your account at [Hugging Face Tokens](https://huggingface.co/settings/tokens).\n",
    "\n",
    "You'll require a Hugging Face API token to access Llama-3.1 8B. Generate your token at Hugging Face Tokens and request access for Llama-3.1 8B. Tokens typically start with \"hf_\".\n",
    "\n",
    "Run the following interactive block in your Jupyter notebook to set up the token:\n",
    "\n",
    "**Note**: Uncheck the \"Add token as Git credential\" option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d549b7",
   "metadata": {
    "id": "b4d549b7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061ca83a25d54593b2ce6e6cbba8e818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login, HfApi\n",
    "\n",
    "# Prompt the user to log in\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b8452",
   "metadata": {
    "id": "297b8452"
   },
   "source": [
    "Verify that your token was accepted correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d624e4",
   "metadata": {
    "id": "87d624e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token validated successfully! Logged in as: Chamath\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    api = HfApi()\n",
    "    user_info = api.whoami()\n",
    "    print(f\"Token validated successfully! Logged in as: {user_info['name']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Token validation failed. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d0a5f3",
   "metadata": {
    "id": "d0d0a5f3"
   },
   "source": [
    "## Run the training script\n",
    "\n",
    "This section describes how to run the training script, with an explanation of the key parameters.\n",
    "\n",
    "### Single-node training overview\n",
    "\n",
    "The training process involves running a pre-configured script that initializes and executes the training of the Llama-3.1 model. The script leverages the Megatron-LM framework and mock data to simulate a full training pipeline. This approach ensures your environment is configured correctly and is functional for real-world use cases.\n",
    "\n",
    "Before running the script, ensure all environment variables are set correctly.\n",
    "\n",
    "### Key parameters for training:\n",
    "\n",
    "* **Batch size (`BS`)**: Set this to `64` for optimal GPU usage.\n",
    "* **Sequence length (`SEQ_LENGTH`)**: Input sequence length, set to `4096`.\n",
    "* **Tensor parallelism (`TP`)**: Set this to `8` for efficient parallelism if using 8 GPUs else `1` if using a single GPUs.\n",
    "* **Precision (`TE_FP8`)**: Set this to `0` for `BF16` precision.\n",
    "\n",
    "### Run the training script\n",
    "\n",
    "Use the following command to train the model on a single node:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb180bf",
   "metadata": {
    "id": "7fb180bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO_TRAINING=0\n",
      "Single node setup, skipping NCCL and GLOO socket interface settings.\n",
      "experiment/1nodes_rank0_train_8B_mbs2_bs64_tp1_pp1_cp1_iter10/TE_FP8_0/2025-10-08_19-17-56/output_perf.log\n",
      "[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:290: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias, allreduce_dgrad):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:301: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:393: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:433: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "[aiter] start build [module_aiter_enum] under /workspace/aiter/aiter/jit/build/module_aiter_enum\n",
      "\u001b[92mSuccessfully preprocessed all matching files.\u001b[0m\n",
      "[aiter] finish build [module_aiter_enum], cost 20.56235192s\n",
      "/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\n",
      "  warnings.warn(\"Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0\", UserWarning)\n",
      "/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0\n",
      "  warnings.warn(self.msg)\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron plugin due to: ImportError(\"cannot import name 'get_tensor_model_parallel_group_if_none' from 'megatron.core.utils' (/shared-docker/Megatron-LM/megatron/core/utils.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "/opt/venv/lib/python3.10/site-packages/modelopt/torch/utils/import_utils.py:32: UserWarning: Failed to import megatron_eagle plugin due to: ImportError(\"cannot import name 'get_expert_tensor_parallel_world_size' from 'megatron.core.parallel_state' (/shared-docker/Megatron-LM/megatron/core/parallel_state.py)\"). You may ignore this warning if you do not need this plugin.\n",
      "  warnings.warn(\n",
      "using world size: 1, data-parallel size: 1, context-parallel size: 1, tensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0\n",
      "WARNING: overriding default arguments for tokenizer_type:GPT2BPETokenizer                        with tokenizer_type:HuggingFaceTokenizer\n",
      "accumulate and all-reduce gradients in fp32 for bfloat16 data type.\n",
      "using torch.bfloat16 for parameters ...\n",
      "------------------------ arguments ------------------------\n",
      "  accumulate_allreduce_grads_in_fp32 .............. True\n",
      "  adam_beta1 ...................................... 0.9\n",
      "  adam_beta2 ...................................... 0.999\n",
      "  adam_eps ........................................ 1e-08\n",
      "  add_bias_linear ................................. False\n",
      "  add_position_embedding .......................... False\n",
      "  add_qkv_bias .................................... False\n",
      "  adlr_autoresume ................................. False\n",
      "  adlr_autoresume_interval ........................ 1000\n",
      "  align_grad_reduce ............................... True\n",
      "  align_param_gather .............................. False\n",
      "  app_tag_run_name ................................ None\n",
      "  app_tag_run_version ............................. 0.0.0\n",
      "  apply_layernorm_1p .............................. False\n",
      "  apply_query_key_layer_scaling ................... False\n",
      "  apply_residual_connection_post_layernorm ........ False\n",
      "  apply_rope_fusion ............................... True\n",
      "  async_save ...................................... None\n",
      "  async_tensor_model_parallel_allreduce ........... False\n",
      "  attention_dropout ............................... 0.0\n",
      "  attention_softmax_in_fp32 ....................... False\n",
      "  auto_detect_ckpt_format ......................... False\n",
      "  barrier_with_L1_time ............................ True\n",
      "  bert_binary_head ................................ True\n",
      "  bert_embedder_type .............................. megatron\n",
      "  bert_load ....................................... None\n",
      "  bf16 ............................................ True\n",
      "  bias_dropout_fusion ............................. True\n",
      "  bias_gelu_fusion ................................ False\n",
      "  bias_swiglu_fusion .............................. True\n",
      "  biencoder_projection_dim ........................ 0\n",
      "  biencoder_shared_query_context_model ............ False\n",
      "  block_data_path ................................. None\n",
      "  calculate_per_token_loss ........................ False\n",
      "  check_for_nan_in_loss_and_grad .................. True\n",
      "  check_weight_hash_across_dp_replicas_interval ... None\n",
      "  ckpt_assume_constant_structure .................. False\n",
      "  ckpt_convert_format ............................. None\n",
      "  ckpt_convert_save ............................... None\n",
      "  ckpt_convert_update_legacy_dist_opt_format ...... False\n",
      "  ckpt_format ..................................... torch_dist\n",
      "  ckpt_fully_parallel_load ........................ False\n",
      "  ckpt_fully_parallel_save ........................ True\n",
      "  ckpt_fully_parallel_save_deprecated ............. False\n",
      "  ckpt_step ....................................... None\n",
      "  classes_fraction ................................ 1.0\n",
      "  clip_grad ....................................... 1.0\n",
      "  clone_scatter_output_in_embedding ............... True\n",
      "  config_logger_dir ............................... \n",
      "  consumed_train_samples .......................... 0\n",
      "  consumed_valid_samples .......................... 0\n",
      "  context_parallel_size ........................... 1\n",
      "  create_attention_mask_in_dataloader ............. True\n",
      "  cross_entropy_loss_fusion ....................... False\n",
      "  data_cache_path ................................. None\n",
      "  data_parallel_random_init ....................... False\n",
      "  data_parallel_size .............................. 1\n",
      "  data_path ....................................... None\n",
      "  data_per_class_fraction ......................... 1.0\n",
      "  data_sharding ................................... True\n",
      "  dataloader_type ................................. cyclic\n",
      "  ddp_average_in_collective ....................... False\n",
      "  ddp_bucket_size ................................. None\n",
      "  decoder_first_pipeline_num_layers ............... None\n",
      "  decoder_last_pipeline_num_layers ................ None\n",
      "  decoder_num_layers .............................. None\n",
      "  decoder_seq_length .............................. None\n",
      "  decoupled_lr .................................... None\n",
      "  decoupled_min_lr ................................ None\n",
      "  decrease_batch_size_if_needed ................... False\n",
      "  defer_embedding_wgrad_compute ................... False\n",
      "  deprecated_use_mcore_models ..................... True\n",
      "  deterministic_mode .............................. False\n",
      "  dino_bottleneck_size ............................ 256\n",
      "  dino_freeze_last_layer .......................... 1\n",
      "  dino_head_hidden_size ........................... 2048\n",
      "  dino_local_crops_number ......................... 10\n",
      "  dino_local_img_size ............................. 96\n",
      "  dino_norm_last_layer ............................ False\n",
      "  dino_teacher_temp ............................... 0.07\n",
      "  dino_warmup_teacher_temp ........................ 0.04\n",
      "  dino_warmup_teacher_temp_epochs ................. 30\n",
      "  disable_straggler_on_startup .................... False\n",
      "  disable_te_fused_rope ........................... False\n",
      "  dist_ckpt_format_deprecated ..................... None\n",
      "  dist_ckpt_strictness ............................ assume_ok_unexpected\n",
      "  distribute_saved_activations .................... False\n",
      "  distributed_backend ............................. nccl\n",
      "  distributed_timeout_minutes ..................... 120\n",
      "  embedding_path .................................. None\n",
      "  empty_unused_memory_level ....................... 0\n",
      "  enable_ft_package ............................... False\n",
      "  enable_one_logger ............................... True\n",
      "  encoder_num_layers .............................. 32\n",
      "  encoder_pipeline_model_parallel_size ............ 0\n",
      "  encoder_seq_length .............................. 4096\n",
      "  encoder_tensor_model_parallel_size .............. 0\n",
      "  end_weight_decay ................................ 0.1\n",
      "  eod_mask_loss ................................... False\n",
      "  eval_interval ................................... 320000\n",
      "  eval_iters ...................................... -1\n",
      "  evidence_data_path .............................. None\n",
      "  exit_duration_in_mins ........................... None\n",
      "  exit_interval ................................... None\n",
      "  exit_on_missing_checkpoint ...................... False\n",
      "  exit_signal_handler ............................. False\n",
      "  expert_model_parallel_size ...................... 1\n",
      "  ffn_hidden_size ................................. 14336\n",
      "  finetune ........................................ False\n",
      "  fp16 ............................................ False\n",
      "  fp16_lm_cross_entropy ........................... False\n",
      "  fp32_residual_connection ........................ False\n",
      "  fp8 ............................................. None\n",
      "  fp8_amax_compute_algo ........................... most_recent\n",
      "  fp8_amax_history_len ............................ 1\n",
      "  fp8_interval .................................... 1\n",
      "  fp8_margin ...................................... 0\n",
      "  fp8_param_gather ................................ False\n",
      "  fp8_wgrad ....................................... True\n",
      "  global_batch_size ............................... 64\n",
      "  gradient_accumulation_fusion .................... False\n",
      "  group_query_attention ........................... True\n",
      "  head_lr_mult .................................... 1.0\n",
      "  hidden_dropout .................................. 0.0\n",
      "  hidden_size ..................................... 4096\n",
      "  hybrid_attention_ratio .......................... 0.0\n",
      "  hybrid_mlp_ratio ................................ 0.0\n",
      "  hybrid_override_pattern ......................... None\n",
      "  hysteresis ...................................... 2\n",
      "  ict_head_size ................................... None\n",
      "  ict_load ........................................ None\n",
      "  img_h ........................................... 224\n",
      "  img_w ........................................... 224\n",
      "  indexer_batch_size .............................. 128\n",
      "  indexer_log_interval ............................ 1000\n",
      "  inference_batch_times_seqlen_threshold .......... 512\n",
      "  init_method_std ................................. 0.02\n",
      "  init_method_xavier_uniform ...................... False\n",
      "  initial_loss_scale .............................. 4294967296\n",
      "  iter_per_epoch .................................. 1250\n",
      "  kv_channels ..................................... 128\n",
      "  kv_lora_rank .................................... 32\n",
      "  lazy_mpu_init ................................... None\n",
      "  load ............................................ None\n",
      "  local_rank ...................................... 0\n",
      "  log_interval .................................... 1\n",
      "  log_loss_scale_to_tensorboard ................... True\n",
      "  log_memory_to_tensorboard ....................... False\n",
      "  log_num_zeros_in_grad ........................... False\n",
      "  log_params_norm ................................. False\n",
      "  log_progress .................................... False\n",
      "  log_straggler ................................... False\n",
      "  log_throughput .................................. True\n",
      "  log_timers_to_tensorboard ....................... False\n",
      "  log_validation_ppl_to_tensorboard ............... False\n",
      "  log_world_size_to_tensorboard ................... False\n",
      "  logging_level ................................... None\n",
      "  loss_scale ...................................... None\n",
      "  loss_scale_window ............................... 1000\n",
      "  lr .............................................. 0.0001\n",
      "  lr_decay_iters .................................. 320000\n",
      "  lr_decay_samples ................................ None\n",
      "  lr_decay_style .................................. cosine\n",
      "  lr_warmup_fraction .............................. None\n",
      "  lr_warmup_init .................................. 0.0\n",
      "  lr_warmup_iters ................................. 0\n",
      "  lr_warmup_samples ............................... 0\n",
      "  lr_wsd_decay_iters .............................. None\n",
      "  lr_wsd_decay_samples ............................ None\n",
      "  lr_wsd_decay_style .............................. exponential\n",
      "  make_vocab_size_divisible_by .................... 128\n",
      "  manual_gc ....................................... False\n",
      "  manual_gc_eval .................................. True\n",
      "  manual_gc_interval .............................. 0\n",
      "  mask_factor ..................................... 1.0\n",
      "  mask_prob ....................................... 0.15\n",
      "  mask_type ....................................... random\n",
      "  masked_softmax_fusion ........................... False\n",
      "  max_position_embeddings ......................... 128000\n",
      "  max_tokens_to_oom ............................... 12000\n",
      "  merge_file ...................................... None\n",
      "  micro_batch_size ................................ 2\n",
      "  min_loss_scale .................................. 1.0\n",
      "  min_lr .......................................... 1e-05\n",
      "  mmap_bin_files .................................. True\n",
      "  mock_data ....................................... True\n",
      "  moe_aux_loss_coeff .............................. 0.0\n",
      "  moe_expert_capacity_factor ...................... None\n",
      "  moe_extended_tp ................................. False\n",
      "  moe_grouped_gemm ................................ False\n",
      "  moe_input_jitter_eps ............................ None\n",
      "  moe_layer_recompute ............................. False\n",
      "  moe_pad_expert_input_to_capacity ................ False\n",
      "  moe_per_layer_logging ........................... False\n",
      "  moe_router_load_balancing_type .................. aux_loss\n",
      "  moe_router_pre_softmax .......................... False\n",
      "  moe_router_topk ................................. 2\n",
      "  moe_shared_expert_intermediate_size ............. None\n",
      "  moe_shared_expert_overlap ....................... False\n",
      "  moe_token_dispatcher_type ....................... allgather\n",
      "  moe_token_drop_policy ........................... probs\n",
      "  moe_use_upcycling ............................... False\n",
      "  moe_z_loss_coeff ................................ None\n",
      "  multi_latent_attention .......................... False\n",
      "  nccl_communicator_config_path ................... None\n",
      "  no_load_optim ................................... None\n",
      "  no_load_rng ..................................... None\n",
      "  no_persist_layer_norm ........................... False\n",
      "  no_save_optim ................................... True\n",
      "  no_save_rng ..................................... None\n",
      "  non_persistent_ckpt_type ........................ None\n",
      "  non_persistent_global_ckpt_dir .................. None\n",
      "  non_persistent_local_ckpt_algo .................. fully_parallel\n",
      "  non_persistent_local_ckpt_dir ................... None\n",
      "  non_persistent_save_interval .................... None\n",
      "  norm_epsilon .................................... 1e-05\n",
      "  normalization ................................... RMSNorm\n",
      "  num_attention_heads ............................. 32\n",
      "  num_channels .................................... 3\n",
      "  num_classes ..................................... 1000\n",
      "  num_dataset_builder_threads ..................... 1\n",
      "  num_experts ..................................... None\n",
      "  num_layers ...................................... 32\n",
      "  num_layers_per_virtual_pipeline_stage ........... None\n",
      "  num_query_groups ................................ 8\n",
      "  num_workers ..................................... 8\n",
      "  one_logger_async ................................ False\n",
      "  one_logger_project .............................. megatron-lm\n",
      "  one_logger_run_name ............................. None\n",
      "  onnx_safe ....................................... None\n",
      "  openai_gelu ..................................... False\n",
      "  optimizer ....................................... adam\n",
      "  output_bert_embeddings .......................... False\n",
      "  overlap_grad_reduce ............................. True\n",
      "  overlap_p2p_comm ................................ False\n",
      "  overlap_param_gather ............................ True\n",
      "  overlap_param_gather_with_optimizer_step ........ False\n",
      "  override_opt_param_scheduler .................... False\n",
      "  params_dtype .................................... torch.bfloat16\n",
      "  patch_dim ....................................... 16\n",
      "  perform_initialization .......................... True\n",
      "  pipeline_model_parallel_size .................... 1\n",
      "  pipeline_model_parallel_split_rank .............. None\n",
      "  position_embedding_type ......................... rope\n",
      "  pretrained_checkpoint ........................... None\n",
      "  profile ......................................... False\n",
      "  profile_ranks ................................... [0]\n",
      "  profile_step_end ................................ 12\n",
      "  profile_step_start .............................. 10\n",
      "  q_lora_rank ..................................... None\n",
      "  qk_head_dim ..................................... 128\n",
      "  qk_layernorm .................................... False\n",
      "  qk_pos_emb_head_dim ............................. 64\n",
      "  query_in_block_prob ............................. 0.1\n",
      "  rampup_batch_size ............................... None\n",
      "  rank ............................................ 0\n",
      "  recompute_granularity ........................... None\n",
      "  recompute_method ................................ None\n",
      "  recompute_num_layers ............................ None\n",
      "  renormalize_blend_weights ....................... False\n",
      "  reset_attention_mask ............................ False\n",
      "  reset_position_ids .............................. False\n",
      "  retriever_report_topk_accuracies ................ []\n",
      "  retriever_score_scaling ......................... False\n",
      "  retriever_seq_length ............................ 256\n",
      "  retro_add_retriever ............................. False\n",
      "  retro_attention_gate ............................ 1\n",
      "  retro_cyclic_train_iters ........................ None\n",
      "  retro_encoder_attention_dropout ................. 0.1\n",
      "  retro_encoder_hidden_dropout .................... 0.1\n",
      "  retro_encoder_layers ............................ 2\n",
      "  retro_num_neighbors ............................. 2\n",
      "  retro_num_retrieved_chunks ...................... 2\n",
      "  retro_project_dir ............................... None\n",
      "  retro_verify_neighbor_count ..................... True\n",
      "  rotary_base ..................................... 10000\n",
      "  rotary_interleaved .............................. False\n",
      "  rotary_percent .................................. 1.0\n",
      "  rotary_scaling_factor ........................... 1.0\n",
      "  rotary_seq_len_interpolation_factor ............. None\n",
      "  s3_cache_path ................................... None\n",
      "  sample_rate ..................................... 1.0\n",
      "  save ............................................ None\n",
      "  save_interval ................................... 5000\n",
      "  scatter_gather_tensors_in_pipeline .............. True\n",
      "  seed ............................................ 1234\n",
      "  seq_length ...................................... 4096\n",
      "  sequence_parallel ............................... False\n",
      "  sgd_momentum .................................... 0.9\n",
      "  short_seq_prob .................................. 0.1\n",
      "  skip_train ...................................... False\n",
      "  skipped_train_samples ........................... 0\n",
      "  spec ............................................ None\n",
      "  split ........................................... None\n",
      "  squared_relu .................................... False\n",
      "  standalone_embedding_stage ...................... False\n",
      "  start_weight_decay .............................. 0.1\n",
      "  straggler_ctrlr_port ............................ 65535\n",
      "  straggler_minmax_count .......................... 1\n",
      "  swiglu .......................................... True\n",
      "  swin_backbone_type .............................. tiny\n",
      "  tensor_model_parallel_size ...................... 1\n",
      "  tensorboard_dir ................................. experiment/1nodes_rank0_train_8B_mbs2_bs64_tp1_pp1_cp1_iter10/TE_FP8_0/2025-10-08_19-17-56\n",
      "  tensorboard_log_interval ........................ 1\n",
      "  tensorboard_queue_size .......................... 1000\n",
      "  test_data_path .................................. None\n",
      "  test_mode ....................................... False\n",
      "  tiktoken_num_special_tokens ..................... 1000\n",
      "  tiktoken_pattern ................................ None\n",
      "  tiktoken_special_tokens ......................... None\n",
      "  timing_log_level ................................ 0\n",
      "  timing_log_option ............................... minmax\n",
      "  titles_data_path ................................ None\n",
      "  tokenizer_model ................................. meta-llama/Llama-3.1-8B\n",
      "  tokenizer_type .................................. HuggingFaceTokenizer\n",
      "  tp_comm_bootstrap_backend ....................... nccl\n",
      "  tp_comm_bulk_dgrad .............................. True\n",
      "  tp_comm_bulk_wgrad .............................. True\n",
      "  tp_comm_overlap ................................. False\n",
      "  tp_comm_overlap_ag .............................. True\n",
      "  tp_comm_overlap_cfg ............................. None\n",
      "  tp_comm_overlap_rs .............................. True\n",
      "  tp_comm_overlap_rs_dgrad ........................ False\n",
      "  tp_comm_split_ag ................................ True\n",
      "  tp_comm_split_rs ................................ True\n",
      "  train_data_path ................................. None\n",
      "  train_iters ..................................... 10\n",
      "  train_samples ................................... None\n",
      "  train_sync_interval ............................. None\n",
      "  transformer_impl ................................ transformer_engine\n",
      "  transformer_pipeline_model_parallel_size ........ 1\n",
      "  untie_embeddings_and_output_weights ............. True\n",
      "  use_checkpoint_args ............................. False\n",
      "  use_checkpoint_opt_param_scheduler .............. False\n",
      "  use_cpu_initialization .......................... None\n",
      "  use_dist_ckpt ................................... True\n",
      "  use_dist_ckpt_deprecated ........................ False\n",
      "  use_distributed_optimizer ....................... True\n",
      "  use_flash_attn .................................. True\n",
      "  use_legacy_models ............................... False\n",
      "  use_one_sent_docs ............................... False\n",
      "  use_pytorch_profiler ............................ False\n",
      "  use_ring_exchange_p2p ........................... False\n",
      "  use_rope_scaling ................................ False\n",
      "  use_rotary_position_embeddings .................. False\n",
      "  use_tp_pp_dp_mapping ............................ False\n",
      "  v_head_dim ...................................... 128\n",
      "  valid_data_path ................................. None\n",
      "  variable_seq_lengths ............................ False\n",
      "  virtual_pipeline_model_parallel_size ............ None\n",
      "  vision_backbone_type ............................ vit\n",
      "  vision_pretraining .............................. False\n",
      "  vision_pretraining_type ......................... classify\n",
      "  vocab_extra_ids ................................. 0\n",
      "  vocab_file ...................................... None\n",
      "  vocab_size ...................................... None\n",
      "  wandb_exp_name .................................. \n",
      "  wandb_project ................................... \n",
      "  wandb_save_dir .................................. \n",
      "  weight_decay .................................... 0.1\n",
      "  weight_decay_incr_style ......................... constant\n",
      "  wgrad_deferral_limit ............................ 0\n",
      "  world_size ...................................... 1\n",
      "  yaml_cfg ........................................ None\n",
      "-------------------- end of arguments ---------------------\n",
      "INFO:megatron.core.num_microbatches_calculator:setting number of microbatches to constant 32\n",
      "> building HuggingFaceTokenizer tokenizer ...\n",
      " > padded vocab (size: 128256) with 0 dummy tokens (new size: 128256)\n",
      "> setting tensorboard ...\n",
      "WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it\n",
      "> initializing torch distributed ...\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "> initialized tensor model parallel with size 1\n",
      "> initialized pipeline model parallel with size 1\n",
      "> setting random seeds to 1234 ...\n",
      "> compiling dataset index builder ...\n",
      "make: Entering directory '/shared-docker/Megatron-LM/megatron/core/datasets'\n",
      "g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/opt/venv/lib/python3.10/site-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so\n",
      "In file included from \u001b[01m\u001b[Khelpers.cpp:12\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/opt/venv/lib/python3.10/site-packages/pybind11/include/pybind11/numpy.h:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[Kvoid build_exhaustive_blending_indices(pybind11::array_t<short int>&, pybind11::array_t<long int>&, const pybind11::array_t<long int>&, int32_t)\u001b[m\u001b[Kâ€™:\n",
      "\u001b[01m\u001b[K/opt/venv/lib/python3.10/site-packages/pybind11/include/pybind11/numpy.h:633:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kerror_argmax\u001b[m\u001b[Kâ€™ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "  633 |     return \u001b[01;35m\u001b[Ki * strides[\u001b[m\u001b[KDim] + byte_offset_unsafe<Dim + 1>(strides, index...);\n",
      "      |            \u001b[01;35m\u001b[K~~^~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Khelpers.cpp:49:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kerror_argmax\u001b[m\u001b[Kâ€™ was declared here\n",
      "   49 |     int64_t \u001b[01;36m\u001b[Kerror_argmax\u001b[m\u001b[K;\n",
      "      |             \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "make: Leaving directory '/shared-docker/Megatron-LM/megatron/core/datasets'\n",
      ">>> done with dataset index builder. Compilation time: 4.117 seconds\n",
      "WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.\n",
      "> compiling and loading fused kernels ...\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank0]:[W1008 19:18:31.182906372 ProcessGroupNCCL.cpp:5059] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.\n",
      ">>> done with compiling and loading fused kernels. Compilation time: 5.460 seconds\n",
      "[rank0]:[W1008 19:18:36.640478049 init.cpp:772] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())\n",
      "time to initialize megatron (seconds): 13.175\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[after megatron is initialized] datetime: 2025-10-08 19:18:39 \n",
      "building GPT model ...\n",
      " > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 8030261248\n",
      "INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=False, fp8_param_gather=False)\n",
      "INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 98\n",
      "Params for bucket 1 (525336576 elements):\n",
      "\tmodule.output_layer.weight\n",
      "Params for bucket 2 (58724352 elements):\n",
      "\tmodule.decoder.final_layernorm.weight\n",
      "\tmodule.decoder.layers.31.mlp.linear_fc2.weight\n",
      "Params for bucket 3 (117440512 elements):\n",
      "\tmodule.decoder.layers.31.mlp.linear_fc1.weight\n",
      "Params for bucket 4 (41951232 elements):\n",
      "\tmodule.decoder.layers.31.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.31.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.31.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.31.self_attention.linear_proj.weight\n",
      "Params for bucket 5 (58720256 elements):\n",
      "\tmodule.decoder.layers.30.mlp.linear_fc2.weight\n",
      "Params for bucket 6 (117440512 elements):\n",
      "\tmodule.decoder.layers.30.mlp.linear_fc1.weight\n",
      "Params for bucket 7 (41951232 elements):\n",
      "\tmodule.decoder.layers.30.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.30.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.30.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.30.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 8 (58720256 elements):\n",
      "\tmodule.decoder.layers.29.mlp.linear_fc2.weight\n",
      "Params for bucket 9 (117440512 elements):\n",
      "\tmodule.decoder.layers.29.mlp.linear_fc1.weight\n",
      "Params for bucket 10 (41951232 elements):\n",
      "\tmodule.decoder.layers.29.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.29.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.29.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.29.self_attention.linear_qkv.weight\n",
      "Params for bucket 11 (58720256 elements):\n",
      "\tmodule.decoder.layers.28.mlp.linear_fc2.weight\n",
      "Params for bucket 12 (117440512 elements):\n",
      "\tmodule.decoder.layers.28.mlp.linear_fc1.weight\n",
      "Params for bucket 13 (41951232 elements):\n",
      "\tmodule.decoder.layers.28.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.28.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.28.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.28.self_attention.linear_proj.weight\n",
      "Params for bucket 14 (58720256 elements):\n",
      "\tmodule.decoder.layers.27.mlp.linear_fc2.weight\n",
      "Params for bucket 15 (117440512 elements):\n",
      "\tmodule.decoder.layers.27.mlp.linear_fc1.weight\n",
      "Params for bucket 16 (41951232 elements):\n",
      "\tmodule.decoder.layers.27.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.27.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.27.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.27.self_attention.linear_proj.weight\n",
      "Params for bucket 17 (58720256 elements):\n",
      "\tmodule.decoder.layers.26.mlp.linear_fc2.weight\n",
      "Params for bucket 18 (117440512 elements):\n",
      "\tmodule.decoder.layers.26.mlp.linear_fc1.weight\n",
      "Params for bucket 19 (41951232 elements):\n",
      "\tmodule.decoder.layers.26.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.26.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.26.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.26.self_attention.linear_proj.weight\n",
      "Params for bucket 20 (58720256 elements):\n",
      "\tmodule.decoder.layers.25.mlp.linear_fc2.weight\n",
      "Params for bucket 21 (117440512 elements):\n",
      "\tmodule.decoder.layers.25.mlp.linear_fc1.weight\n",
      "Params for bucket 22 (41951232 elements):\n",
      "\tmodule.decoder.layers.25.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.25.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.25.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.25.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 23 (58720256 elements):\n",
      "\tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "Params for bucket 24 (117440512 elements):\n",
      "\tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "Params for bucket 25 (41951232 elements):\n",
      "\tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "Params for bucket 26 (58720256 elements):\n",
      "\tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "Params for bucket 27 (117440512 elements):\n",
      "\tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "Params for bucket 28 (41951232 elements):\n",
      "\tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.23.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.23.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.23.self_attention.linear_proj.weight\n",
      "Params for bucket 29 (58720256 elements):\n",
      "\tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "Params for bucket 30 (117440512 elements):\n",
      "\tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "Params for bucket 31 (41951232 elements):\n",
      "\tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.22.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.22.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.22.self_attention.linear_proj.weight\n",
      "Params for bucket 32 (58720256 elements):\n",
      "\tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "Params for bucket 33 (117440512 elements):\n",
      "\tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "Params for bucket 34 (41951232 elements):\n",
      "\tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.21.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.21.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.21.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 35 (58720256 elements):\n",
      "\tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "Params for bucket 36 (117440512 elements):\n",
      "\tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "Params for bucket 37 (41951232 elements):\n",
      "\tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.20.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.20.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.20.self_attention.linear_qkv.weight\n",
      "Params for bucket 38 (58720256 elements):\n",
      "\tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "Params for bucket 39 (117440512 elements):\n",
      "\tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "Params for bucket 40 (41951232 elements):\n",
      "\tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.19.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.19.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.19.self_attention.linear_proj.weight\n",
      "Params for bucket 41 (58720256 elements):\n",
      "\tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "Params for bucket 42 (117440512 elements):\n",
      "\tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "Params for bucket 43 (41951232 elements):\n",
      "\tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.18.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.18.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.18.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 44 (58720256 elements):\n",
      "\tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "Params for bucket 45 (117440512 elements):\n",
      "\tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "Params for bucket 46 (41951232 elements):\n",
      "\tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "Params for bucket 47 (58720256 elements):\n",
      "\tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "Params for bucket 48 (117440512 elements):\n",
      "\tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "Params for bucket 49 (41951232 elements):\n",
      "\tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.16.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.16.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.16.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 50 (58720256 elements):\n",
      "\tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "Params for bucket 51 (117440512 elements):\n",
      "\tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "Params for bucket 52 (41951232 elements):\n",
      "\tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.15.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.15.self_attention.linear_qkv.weight\n",
      "Params for bucket 53 (58720256 elements):\n",
      "\tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "Params for bucket 54 (117440512 elements):\n",
      "\tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "Params for bucket 55 (41951232 elements):\n",
      "\tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.14.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.14.self_attention.linear_proj.weight\n",
      "Params for bucket 56 (58720256 elements):\n",
      "\tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "Params for bucket 57 (117440512 elements):\n",
      "\tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "Params for bucket 58 (41951232 elements):\n",
      "\tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.13.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.13.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 59 (58720256 elements):\n",
      "\tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "Params for bucket 60 (117440512 elements):\n",
      "\tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "Params for bucket 61 (41951232 elements):\n",
      "\tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.12.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.12.self_attention.linear_proj.weight\n",
      "Params for bucket 62 (58720256 elements):\n",
      "\tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "Params for bucket 63 (117440512 elements):\n",
      "\tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "Params for bucket 64 (41951232 elements):\n",
      "\tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.11.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.11.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 65 (58720256 elements):\n",
      "\tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "Params for bucket 66 (117440512 elements):\n",
      "\tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "Params for bucket 67 (41951232 elements):\n",
      "\tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "Params for bucket 68 (58720256 elements):\n",
      "\tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "Params for bucket 69 (117440512 elements):\n",
      "\tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "Params for bucket 70 (41951232 elements):\n",
      "\tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.9.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.9.self_attention.linear_proj.weight\n",
      "Params for bucket 71 (58720256 elements):\n",
      "\tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "Params for bucket 72 (117440512 elements):\n",
      "\tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "Params for bucket 73 (41951232 elements):\n",
      "\tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.8.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.8.self_attention.linear_qkv.weight\n",
      "Params for bucket 74 (58720256 elements):\n",
      "\tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "Params for bucket 75 (117440512 elements):\n",
      "\tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "Params for bucket 76 (41951232 elements):\n",
      "\tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.7.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.7.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 77 (58720256 elements):\n",
      "\tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "Params for bucket 78 (117440512 elements):\n",
      "\tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "Params for bucket 79 (41951232 elements):\n",
      "\tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.6.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.6.self_attention.linear_qkv.weight\n",
      "Params for bucket 80 (58720256 elements):\n",
      "\tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "Params for bucket 81 (117440512 elements):\n",
      "\tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "Params for bucket 82 (41951232 elements):\n",
      "\tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.5.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.5.self_attention.linear_qkv.weight\n",
      "Params for bucket 83 (58720256 elements):\n",
      "\tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "Params for bucket 84 (117440512 elements):\n",
      "\tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "Params for bucket 85 (41951232 elements):\n",
      "\tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.4.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.4.self_attention.linear_qkv.weight\n",
      "Params for bucket 86 (58720256 elements):\n",
      "\tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "Params for bucket 87 (117440512 elements):\n",
      "\tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "Params for bucket 88 (41951232 elements):\n",
      "\tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 89 (58720256 elements):\n",
      "\tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "Params for bucket 90 (117440512 elements):\n",
      "\tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "Params for bucket 91 (41951232 elements):\n",
      "\tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "\tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "Params for bucket 92 (58720256 elements):\n",
      "\tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "Params for bucket 93 (117440512 elements):\n",
      "\tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "Params for bucket 94 (41951232 elements):\n",
      "\tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "Params for bucket 95 (58720256 elements):\n",
      "\tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "Params for bucket 96 (117440512 elements):\n",
      "\tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "Params for bucket 97 (41951232 elements):\n",
      "\tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "\tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "\tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "\tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "Params for bucket 98 (525336576 elements):\n",
      "\tmodule.embedding.word_embeddings.weight\n",
      "INFO:megatron.core.optimizer:Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0001, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7a2208304610>, config_logger_dir='')\n",
      "INFO:megatron.core.optimizer_param_scheduler:> learning rate decay style: cosine\n",
      "[after model, optimizer, and learning rate scheduler are built] datetime: 2025-10-08 19:18:39 \n",
      "> building train, validation, and test datasets ...\n",
      " > datasets target sizes (minimum size):\n",
      "    train:      640\n",
      "    validation: -64\n",
      "    test:       -64\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_config:Let mock = True, as both blend and blend_per_split are None\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split = 1,1,1, an arbitrarily even split, as mock is True\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.3333333333333333), (0.3333333333333333, 0.6666666666666666), (0.6666666666666666, 1.0)]\n",
      "> building train, validation, and test datasets for GPT ...\n",
      "INFO:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=MockGPTDataset, sizes=(640, -64, -64), and config=GPTDatasetConfig(random_seed=1234, sequence_length=4096, blend=None, blend_per_split=[None, None, None], renormalize_blend_weights=False, split='1,1,1', split_matrix=[(0, 0.3333333333333333), (0.3333333333333333, 0.6666666666666666), (0.6666666666666666, 1.0)], num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=True, tokenizer=<megatron.training.tokenizer.tokenizer._HuggingFaceTokenizer object at 0x7a22082d0370>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, s3_cache_path=None)\n",
      "INFO:megatron.core.datasets.gpt_dataset:Build and save the MockGPTDataset train indices\n",
      "WARNING:megatron.core.datasets.gpt_dataset:Unable to save the MockGPTDataset indexes because path_to_cache is None\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 16648\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1\n",
      "INFO:megatron.core.datasets.gpt_dataset:Build and save the MockGPTDataset valid indices\n",
      "WARNING:megatron.core.datasets.gpt_dataset:Unable to save the MockGPTDataset indexes because path_to_cache is None\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 16640\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1\n",
      "INFO:megatron.core.datasets.gpt_dataset:Build and save the MockGPTDataset test indices\n",
      "WARNING:megatron.core.datasets.gpt_dataset:Unable to save the MockGPTDataset indexes because path_to_cache is None\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 16671\n",
      "INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1\n",
      "> finished creating GPT datasets ...\n",
      "[after dataloaders are built] datetime: 2025-10-08 19:18:39 \n",
      "done with setup ...\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.\n",
      "  return func(*args, **kwargs)\n",
      "(min, max) time across ranks (ms):\n",
      "    model-and-optimizer-setup ......................: (442.03, 442.03)\n",
      "    train/valid/test-data-iterators-setup ..........: (8.79, 8.79)\n",
      "training ...\n",
      "[before the start of training step] datetime: 2025-10-08 19:18:39 \n",
      "AITER_ASM_DIR set to: /opt/venv/lib/python3.10/site-packages/transformer_engine/aiter/gfx942/\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.\n",
      "  return func(*args, **kwargs)\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.\n",
      "  return func(*args, **kwargs)\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:623: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.\n",
      "  warnings.warn(\n",
      "/shared-docker/Megatron-LM/megatron/core/tensor_parallel/layers.py:623: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.\n",
      "  warnings.warn(\n",
      "/shared-docker/Megatron-LM/megatron/core/distributed/param_and_grad_buffer.py:259: FutureWarning: `torch.distributed._reduce_scatter_base` is a private function and will be deprecated. Please use `torch.distributed.reduce_scatter_tensor` instead.\n",
      "  torch.distributed._reduce_scatter_base(\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      " [2025-10-08 19:19:25] iteration        1/      10 | consumed samples:           64 | elapsed time per iteration (ms): 46184.4 | throughput per GPU (TFLOP/s/GPU): 292.1 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.258631E+01 | loss scale: 1.0 | grad norm: 13.107 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "Number of parameters in transformer layers in billions:  6.98\n",
      "Number of parameters in embedding layers in billions: 1.05\n",
      "Total number of parameters in billions: 8.03\n",
      "Number of parameters in most loaded shard in billions: 8.0305\n",
      "Theoretical memory footprints: weight and optimizer=137853.14 MB\n",
      "[Rank 0] (after 1 iterations) memory (MB) | allocated: 138033.55859375 | max allocated: 138033.57470703125 | reserved: 149810.0 | max reserved: 149810.0\n",
      "/opt/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.\n",
      "  return func(*args, **kwargs)\n",
      " [2025-10-08 19:19:51] iteration        2/      10 | consumed samples:          128 | elapsed time per iteration (ms): 25789.1 | throughput per GPU (TFLOP/s/GPU): 523.2 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 3.872919E+00 | loss scale: 1.0 | grad norm: 11.364 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-08 19:20:17] iteration        3/      10 | consumed samples:          192 | elapsed time per iteration (ms): 25836.9 | throughput per GPU (TFLOP/s/GPU): 522.2 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 9.161057E-01 | loss scale: 1.0 | grad norm: 3.976 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-08 19:20:43] iteration        4/      10 | consumed samples:          256 | elapsed time per iteration (ms): 25809.5 | throughput per GPU (TFLOP/s/GPU): 522.8 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 5.757305E-01 | loss scale: 1.0 | grad norm: 10.312 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-08 19:21:09] iteration        5/      10 | consumed samples:          320 | elapsed time per iteration (ms): 25778.8 | throughput per GPU (TFLOP/s/GPU): 523.4 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 2.550575E-01 | loss scale: 1.0 | grad norm: 1.838 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-08 19:21:34] iteration        6/      10 | consumed samples:          384 | elapsed time per iteration (ms): 25805.6 | throughput per GPU (TFLOP/s/GPU): 522.9 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.902423E-01 | loss scale: 1.0 | grad norm: 1.481 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-08 19:22:00] iteration        7/      10 | consumed samples:          448 | elapsed time per iteration (ms): 25803.1 | throughput per GPU (TFLOP/s/GPU): 522.9 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.527723E-01 | loss scale: 1.0 | grad norm: 1.268 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-08 19:22:26] iteration        8/      10 | consumed samples:          512 | elapsed time per iteration (ms): 25817.6 | throughput per GPU (TFLOP/s/GPU): 522.6 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 1.051414E-01 | loss scale: 1.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-08 19:22:52] iteration        9/      10 | consumed samples:          576 | elapsed time per iteration (ms): 25796.3 | throughput per GPU (TFLOP/s/GPU): 523.0 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 9.012447E-02 | loss scale: 1.0 | grad norm: 1.048 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " [2025-10-08 19:23:18] iteration       10/      10 | consumed samples:          640 | elapsed time per iteration (ms): 25780.3 | throughput per GPU (TFLOP/s/GPU): 523.4 | learning rate: 1.000000E-04 | global batch size:    64 | lm loss: 7.919759E-02 | loss scale: 1.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "/shared-docker/Megatron-LM/megatron/core/optimizer/distrib_optimizer.py:557: UserWarning: `DistributedOptimizer.disable_pre_hook` will be deprecated in a future release. Use `DistributedDataParallel.disable_forward_pre_hook` directly.\n",
      "  warnings.warn(\n",
      "[after training is done] datetime: 2025-10-08 19:23:18 \n",
      "[rank0]:[W1008 19:23:19.856530987 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "throughput per GPU: 522.8285714285714\n",
      "elapsed time per iteration: 25806.82857142857\n",
      "tokens/GPU/s: 10157.931622\n"
     ]
    }
   ],
   "source": [
    "!cd Megatron-LM && TEE_OUTPUT=1 MBS=2 BS=64 TP=1 TE_FP8=0 SEQ_LENGTH=4096  \\\n",
    "TOKENIZER_MODEL='meta-llama/Llama-3.1-8B' MODEL_SIZE='8' \\\n",
    "bash examples/llama/train_llama3.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748d2e8",
   "metadata": {
    "id": "c748d2e8"
   },
   "source": [
    "### Additional details about the command\n",
    "\n",
    "This command configures the training process with the following parameters:\n",
    "\n",
    "* **`TEE_OUTPUT=1`**: Enables logging output to the console.\n",
    "* **`MBS=2`**: Micro-batch size per GPU.\n",
    "* **`BS=64`**: Total batch size across all GPUs.\n",
    "* **`TP=1`**: Tensor parallelism for distributing the model across GPUs.\n",
    "* **`TE_FP8=0`**: Sets the precision to `BF16` for training.\n",
    "* **`SEQ_LENGTH=4096`**: Maximum input sequence length.\n",
    "\n",
    "The training script does the following:\n",
    "* Uses mock data as input.\n",
    "* Trains the Llama-3.1 8B model with the specified configurations.\n",
    "\n",
    "You can customize these parameters based on your hardware and desired configurations by modifying the command details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51275b54",
   "metadata": {
    "id": "51275b54"
   },
   "source": [
    "## Monitor the training progress\n",
    "\n",
    "Monitor the output logs during the training process for the following developments:\n",
    "\n",
    "* **Iteration progress**: The number of completed iterations.\n",
    "* **Loss values**: This indicates the model's learning progress. Lower values suggest better learning.\n",
    "* **GPU utilization**: Ensures the optimal usage of your hardware resources.\n",
    "\n",
    "Logs are printed to the console and saved to a log file within the directory specified by the script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8378cfb",
   "metadata": {
    "id": "a8378cfb"
   },
   "source": [
    "## Key notes\n",
    "\n",
    "* Mock data is for validation only. To use a different dataset, see the [Pretraining with Megatron-LM tutorial](https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/pretrain/setup_tutorial.html).\n",
    "* Tune the hyperparameters based on your hardware. The hyperparameter configuration in this tutorial is based on 1x MI300x GPU.\n",
    "* This example illustrates how to run a training task on a single node. For multi-node training instructions, see the [Pretraining with Megatron-LM tutorial](https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/pretrain/setup_tutorial.html).\n",
    "* Verify the logs for correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7bd548",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b3e1d-792b-4aa0-abdf-a325dafc647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "from typing import Literal, NamedTuple, Optional, TypedDict, Union, get_args\n",
    "\n",
    "from PIL.Image import Image\n",
    "\n",
    "from vllm import LLM, EngineArgs\n",
    "from vllm.entrypoints.score_utils import ScoreMultiModalParam\n",
    "from vllm.multimodal.utils import fetch_image\n",
    "from vllm.utils import FlexibleArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc87cc-d19a-4b5c-abee-58143ab061e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextQuery(TypedDict):\n",
    "    modality: Literal[\"text\"]\n",
    "    text: str\n",
    "\n",
    "\n",
    "class ImageQuery(TypedDict):\n",
    "    modality: Literal[\"image\"]\n",
    "    image: Image\n",
    "\n",
    "\n",
    "class TextImageQuery(TypedDict):\n",
    "    modality: Literal[\"text+image\"]\n",
    "    text: str\n",
    "    image: Image\n",
    "\n",
    "\n",
    "class TextImagesQuery(TypedDict):\n",
    "    modality: Literal[\"text+images\"]\n",
    "    text: str\n",
    "    image: ScoreMultiModalParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf16a5-4fb6-4fa7-9fff-0027429d1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryModality = Literal[\"text\", \"image\", \"text+image\", \"text+images\"]\n",
    "Query = Union[TextQuery, ImageQuery, TextImageQuery, TextImagesQuery]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e755f-2292-4a38-bdd3-1ed895ffe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRequestData(NamedTuple):\n",
    "    engine_args: EngineArgs\n",
    "    prompt: Optional[str] = None\n",
    "    image: Optional[Image] = None\n",
    "    query: Optional[str] = None\n",
    "    documents: Optional[ScoreMultiModalParam] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b65efd-433d-49bc-be88-250117e153ed",
   "metadata": {},
   "source": [
    "### e5-v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959bdf91-7cd4-415d-8091-2885a2d5547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_e5_v(query: Query) -> ModelRequestData:\n",
    "    llama3_template = \"<|start_header_id|>user<|end_header_id|>\\n\\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n \\n\"  # noqa: E501\n",
    "\n",
    "    if query[\"modality\"] == \"text\":\n",
    "        text = query[\"text\"]\n",
    "        prompt = llama3_template.format(f\"{text}\\nSummary above sentence in one word: \")\n",
    "        image = None\n",
    "    elif query[\"modality\"] == \"image\":\n",
    "        prompt = llama3_template.format(\"<image>\\nSummary above image in one word: \")\n",
    "        image = query[\"image\"]\n",
    "    else:\n",
    "        modality = query[\"modality\"]\n",
    "        raise ValueError(f\"Unsupported query modality: '{modality}'\")\n",
    "\n",
    "    engine_args = EngineArgs(\n",
    "        model=\"royokong/e5-v\",\n",
    "        runner=\"pooling\",\n",
    "        max_model_len=4096,\n",
    "        limit_mm_per_prompt={\"image\": 1},\n",
    "    )\n",
    "\n",
    "    return ModelRequestData(\n",
    "        engine_args=engine_args,\n",
    "        prompt=prompt,\n",
    "        image=image,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47495ff3-68e0-4c65-a731-2fa39a0c0177",
   "metadata": {},
   "source": [
    "### VLM2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6ab63-8be8-4bf0-a2f4-e7b1b3bf87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vlm2vec(query: Query) -> ModelRequestData:\n",
    "    if query[\"modality\"] == \"text\":\n",
    "        text = query[\"text\"]\n",
    "        prompt = f\"Find me an everyday image that matches the given caption: {text}\"  # noqa: E501\n",
    "        image = None\n",
    "    elif query[\"modality\"] == \"image\":\n",
    "        prompt = \"<|image_1|> Find a day-to-day image that looks similar to the provided image.\"  # noqa: E501\n",
    "        image = query[\"image\"]\n",
    "    elif query[\"modality\"] == \"text+image\":\n",
    "        text = query[\"text\"]\n",
    "        prompt = (\n",
    "            f\"<|image_1|> Represent the given image with the following question: {text}\"  # noqa: E501\n",
    "        )\n",
    "        image = query[\"image\"]\n",
    "    else:\n",
    "        modality = query[\"modality\"]\n",
    "        raise ValueError(f\"Unsupported query modality: '{modality}'\")\n",
    "\n",
    "    engine_args = EngineArgs(\n",
    "        model=\"TIGER-Lab/VLM2Vec-Full\",\n",
    "        runner=\"pooling\",\n",
    "        max_model_len=4096,\n",
    "        trust_remote_code=True,\n",
    "        mm_processor_kwargs={\"num_crops\": 4},\n",
    "        limit_mm_per_prompt={\"image\": 1},\n",
    "    )\n",
    "\n",
    "    return ModelRequestData(\n",
    "        engine_args=engine_args,\n",
    "        prompt=prompt,\n",
    "        image=image,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912c970-fc97-4b9c-9272-128dd2b7d95c",
   "metadata": {},
   "source": [
    "### jina-reranker-m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f2cfa-39a3-4a70-a6c8-0dac21dd6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_jinavl_reranker(query: Query) -> ModelRequestData:\n",
    "    if query[\"modality\"] != \"text+images\":\n",
    "        raise ValueError(f\"Unsupported query modality: '{query['modality']}'\")\n",
    "\n",
    "    engine_args = EngineArgs(\n",
    "        model=\"jinaai/jina-reranker-m0\",\n",
    "        runner=\"pooling\",\n",
    "        max_model_len=32768,\n",
    "        trust_remote_code=True,\n",
    "        mm_processor_kwargs={\n",
    "            \"min_pixels\": 3136,\n",
    "            \"max_pixels\": 602112,\n",
    "        },\n",
    "        limit_mm_per_prompt={\"image\": 1},\n",
    "    )\n",
    "\n",
    "    return ModelRequestData(\n",
    "        engine_args=engine_args,\n",
    "        query=query[\"text\"],\n",
    "        documents=query[\"image\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22368d0e-4f0d-4deb-a941-e883fa9cffde",
   "metadata": {},
   "source": [
    "## Model Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d162f32-d04b-4612-99cd-84126f3f248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_example_map = {\n",
    "    \"e5_v\": run_e5_v,\n",
    "    \"vlm2vec\": run_vlm2vec,\n",
    "    \"jinavl_reranker\": run_jinavl_reranker,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8c71e-a611-4bb1-8455-13a1cea3199e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893216ae-c681-4337-95fe-7ffbf9da27ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(modality: QueryModality):\n",
    "    if modality == \"text\":\n",
    "        return TextQuery(modality=\"text\", text=\"A dog sitting in the grass\")\n",
    "\n",
    "    if modality == \"image\":\n",
    "        return ImageQuery(\n",
    "            modality=\"image\",\n",
    "            image=fetch_image(\n",
    "                \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/American_Eskimo_Dog.jpg/360px-American_Eskimo_Dog.jpg\"  # noqa: E501\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    if modality == \"text+image\":\n",
    "        return TextImageQuery(\n",
    "            modality=\"text+image\",\n",
    "            text=\"A cat standing in the snow.\",\n",
    "            image=fetch_image(\n",
    "                \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Felis_catus-cat_on_snow.jpg/179px-Felis_catus-cat_on_snow.jpg\"  # noqa: E501\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    if modality == \"text+images\":\n",
    "        return TextImagesQuery(\n",
    "            modality=\"text+images\",\n",
    "            text=\"slm markdown\",\n",
    "            image={\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/handelsblatt-preview.png\"\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\"\n",
    "                        },\n",
    "                    },\n",
    "                ]\n",
    "            },\n",
    "        )\n",
    "\n",
    "    msg = f\"Modality {modality} is not supported.\"\n",
    "    raise ValueError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f7b3a-cbd7-499e-8208-7c7d19ec32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_encode(model: str, modality: QueryModality, seed: Optional[int]):\n",
    "    query = get_query(modality)\n",
    "    req_data = model_example_map[model](query)\n",
    "\n",
    "    # Disable other modalities to save memory\n",
    "    default_limits = {\"image\": 0, \"video\": 0, \"audio\": 0}\n",
    "    req_data.engine_args.limit_mm_per_prompt = default_limits | dict(\n",
    "        req_data.engine_args.limit_mm_per_prompt or {}\n",
    "    )\n",
    "\n",
    "    engine_args = asdict(req_data.engine_args) | {\"seed\": seed}\n",
    "    llm = LLM(**engine_args)\n",
    "\n",
    "    mm_data = {}\n",
    "    if req_data.image is not None:\n",
    "        mm_data[\"image\"] = req_data.image\n",
    "\n",
    "    outputs = llm.embed(\n",
    "        {\n",
    "            \"prompt\": req_data.prompt,\n",
    "            \"multi_modal_data\": mm_data,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    for output in outputs:\n",
    "        print(output.outputs.embedding)\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e50d0-9633-4ab9-8c78-8106256db6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_score(model: str, modality: QueryModality, seed: Optional[int]):\n",
    "    query = get_query(modality)\n",
    "    req_data = model_example_map[model](query)\n",
    "\n",
    "    engine_args = asdict(req_data.engine_args) | {\"seed\": seed}\n",
    "    llm = LLM(**engine_args)\n",
    "\n",
    "    outputs = llm.score(req_data.query, req_data.documents)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print([output.outputs.score for output in outputs])\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

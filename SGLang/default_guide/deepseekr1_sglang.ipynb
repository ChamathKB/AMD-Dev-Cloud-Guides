{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DeepSeek-R1 with SGLang and example applications\n",
    "\n",
    "Throughout this tutorial, you'll leverage AMD GPUs to deploy the powerful language model [DeepSeek-R1-Distill-Qwen-32B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B). The tutorial covers setting up an AI development environment and explores two main practical applications:\n",
    "\n",
    "*  **Advanced chatbot:** Using Open WebUI to create a sophisticated chatbot with web search and file interaction capabilities.\n",
    "*  **Code development assistant:** Installing and utilizing the AI Toolkit Code extension to perform code analysis and pair programming tasks.\n",
    "\n",
    "Let's dive in!\n",
    "\n",
    "**Note**: The same steps can be applied to serve DeepSeek-R1 (671B) on a single AMD MI300X node. For more information about running this model, see [this blog post](https://rocm.blogs.amd.com/artificial-intelligence/DeepSeekR1-Part2/README.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching the SGLang server on AMD GPUs\n",
    "\n",
    "The following runs the `sglang.launch_server` command to initiate the server. Click the + button to open a new tab button inside this Jupyter server next to the current notebook tab. Then click on \"Terminal\" to start a terminal window. Finally, copy the following SGLang command to create your OpenAI-compatible model endpoint.\n",
    "\n",
    "**Important**: This command will download the model from Hugging Face repository, and load the model into your GPU memory. \n",
    "```bash\n",
    "python3 -m sglang.launch_server \\\n",
    "    --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B \\\n",
    "    --port 30000 \\\n",
    "    --trust-remote-code \\\n",
    "    --disable-radix-cache \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --context-length 4000 \\\n",
    "    --api-key \"abc-123\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the model is fully loaded and available. The server should print a message after loading the model indicating the server is ready and the model is fully loaded.\n",
    "\n",
    "Upon a successful launch, your server will be ready to accept incoming requests through an OpenAI-compatible API. \n",
    "Next, we’ll use OpenAI-compatible API calls to test your SGLang server, and ensure that we can get a response from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I need to list three countries and their capitals. Hmm, let's see. I'm a bit new to this, so I'll take it step by step. First, I should think of some countries I know. Well, the United States is a big one, right? I think its capital is Washington, D.C. Yeah, I've heard that before in school. \n",
      "\n",
      "Next, I need to think of another country. Maybe France? I'm pretty sure the capital of France is Paris. That sounds right. Paris is famous for the Eiffel Tower and stuff, so that must be the capital. \n",
      "\n",
      "Now, the third country. Hmm, how about Brazil? I'm not too sure about this one. I think it's Brasília, but wait, wasn't there a time when Rio de Janeiro was the capital? I think they moved the capital to Brasília a while back to develop the interior. So, yeah, I'm pretty confident it's Brasília now. \n",
      "\n",
      "Wait, let me double-check. I know the United States capital is definitely Washington, D.C. France is Paris, that's correct. For Brazil, I'm a bit unsure but I think it's Brasília. Maybe I should think of another country if I'm not sure. What about Canada? The capital of Canada is Ottawa, right? That's another option. Or maybe Italy, Rome is the capital. Hmm, but I already have three, so maybe I'll stick with Brazil. \n",
      "\n",
      "So, to sum up, I'll list the United States with Washington, D.C., France with Paris, and Brazil with Brasília. I think that's correct. I just hope I'm not mixing up the Brazilian capital with another city. I think it's right, but I'm a little unsure. Maybe I should verify it later, but for now, I'll go with that.\n",
      "</think>\n",
      "\n",
      "Here is a list of three countries and their capitals:\n",
      "\n",
      "1. United States - Washington, D.C.\n",
      "2. France - Paris\n",
      "3. Brazil - Brasília\n",
      "\n",
      "These capitals are correctly identified, with Brasília being the capital of Brazil since its establishment as the federal capital in 1960.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:30000/v1\",  # must be http not https\n",
    "    api_key=\"abc-123\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"List 3 countries and their capitals.\"},\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can resume the rest of this tutorial on your own local device. Use the code above on your local device to verify that the endpoint is reachable. Replace `localhost` with your server's public IP when running remotely. Running the following command will provide you the public IP of this server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl ifconfig.me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Advanced chatbot with OpenWebUI \n",
    "\n",
    "**Note**: The rest of this tutorial is designed to be executed on your own local device.\n",
    "\n",
    "Follow the installation instructions from the [Open WebUI GitHub repository](https://github.com/open-webui/open-webui).\n",
    "\n",
    "After installation, configure your endpoint URL in the Open WebUI client as follows:\n",
    "\n",
    "- Navigate to `Settings` as shown in the image below:\n",
    "\n",
    "  ![OpenWebUI Setup 1](./assets/openwebui1.png)\n",
    "\n",
    "- Select `Connections` from the left tab.\n",
    "  - Enter the `URL` so that it matches this format: `http://YOUR_SERVER_PUBLIC_IP:PORT_NUMBER/v1`.\n",
    "  - Enter the `Key` to match the API key you passed to `sglang.launch_server`.\n",
    "  - Enter the model name (under `Model IDs`) that exactly matches the argument you passed to `sglang.launch_server`. For example, `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`. \n",
    "  - Click on the `+` button.\n",
    "  - Click on the `Save` button. \n",
    "\n",
    "  ![OpenWebUI Setup 2](./assets/openwebui2.png)\n",
    "\n",
    "\n",
    "## Chatbot testing with DeepSeek-R1\n",
    "\n",
    "Use Open WebUI to interact with your chatbot. Here is an example prompt:\n",
    "\n",
    "```\n",
    "Imagine facing east. Turn 90° left, then 270° right, then 180° left. Which direction are you facing?\n",
    "```\n",
    "\n",
    "Follow up with a request for code visualization:\n",
    "\n",
    "```\n",
    "Can you give me a simple Python code without importing external libraries to visualize this step-by-step with Unicode arrows?\n",
    "```\n",
    "\n",
    "![OpenWebUI Example](./assets/webui_example.gif)\n",
    "\n",
    "\n",
    "## Code development assistant using the VS Code AI Toolkit\n",
    "\n",
    "Follow these steps to install the AI Toolkit for VS Code extension in VS Code:\n",
    "\n",
    "- Open VS Code.\n",
    "- Navigate to **Extensions** (`Ctrl+Shift+X`).\n",
    "- Search for and install **VS Code AI Toolkit**.\n",
    "- Click on `remote inference` as shown in the image below:\n",
    "\n",
    "  ![AI Toolkit Setup 1](./assets/aitoolkit1.png)\n",
    "\n",
    "- Select `Add a custom model`.\n",
    "\n",
    "  ![AI Toolkit Setup 2](./assets/aitoolkit2.png)\n",
    "\n",
    "- Enter the Open AI-compatible URL matching this format: `http://YOUR_SERVER_PUBLIC_IP:PORT_NUMBER/v1/chat/completions`.\n",
    "\n",
    "  ![AI Toolkit Setup 3](./assets/aitoolkit_url.png)\n",
    "\n",
    "- Enter the model name so that it exactly matches the argument passed to `sglang.launch_server`, for example, `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`.\n",
    "\n",
    "  ![AI Toolkit Setup 4](./assets/aitoolkit3.png)\n",
    "\n",
    "- Press **Enter** to display the model name. \n",
    "\n",
    "  ![AI Toolkit Setup 5](./assets/aitoolkit5.png)\n",
    "\n",
    "- Enter the HTTP header for authorization matching this format `Authorization: Bearer API KEY` exactly as specified, where `API KEY` must match the key you passed to `sglang.launch_server`. If you used the exact same command provided in this tutorial, enter `Authorization: Bearer abc-123`.\n",
    "\n",
    "  ![AI Toolkit Setup 6](./assets/aitoolkit6.png)\n",
    "\n",
    "After you've completed the steps above, your model should be listed under `MY MODELS` on the left. Click your model to start the corresponding playground.\n",
    "\n",
    "  ![AI Toolkit Setup 7](./assets/aitoolkit.png)\n",
    "\n",
    "\n",
    "## Build a snake game \n",
    "\n",
    "In VS Code, make this request:\n",
    "\n",
    "```\n",
    "\"Can you build a classic snake game? Include 'Powered by DeepSeek-R1 on AMD MI300X' in the corner. Use Python.\"\n",
    "```\n",
    "\n",
    "## Optional advanced challenge: Pac-Man\n",
    "Try building a Pac-Man game with a maximum of three prompts.\n",
    "\n",
    "\n",
    "Happy coding! If you encounter issues or have questions, don’t hesitate to ask or raise an issue on our [Github page](https://github.com/ROCm/gpuaidev)!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
